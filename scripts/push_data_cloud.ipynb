{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcce6d9a",
   "metadata": {},
   "source": [
    "### X√≥a DB tr√™n Neo4j Browser tr∆∞·ªõc n·∫øu c√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1d9f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu quy tr√¨nh x√≥a s·ªï to√†n b·ªô d·ªØ li·ªáu...\n",
      "   - ƒêang t√¨m v√† x√≥a Constraints...\n",
      "     Deleted constraint: constraint_1e6bab2b\n",
      "     Deleted constraint: constraint_43f9c6cd\n",
      "     Deleted constraint: constraint_4b2945cd\n",
      "     Deleted constraint: constraint_82b3e63a\n",
      "     Deleted constraint: constraint_e578272a\n",
      "   - ƒêang t√¨m v√† x√≥a Indexes...\n",
      "     Deleted index: general_info_index\n",
      "     Deleted index: searchable_index\n",
      "     Deleted index: stopNameIndex\n",
      "     Deleted index: stop_id_idx\n",
      "     Deleted index: stop_name_idx\n",
      "   - ƒêang x√≥a s·∫°ch Node v√† Relationship...\n",
      "‚ú® XONG! Database gi·ªù tr·∫Øng tr∆°n nh∆∞ t·ªù gi·∫•y.\n",
      "üîç Ki·ªÉm tra l·∫°i: S·ªë l∆∞·ª£ng node hi·ªán t·∫°i l√†: 0\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# C·∫•u h√¨nh k·∫øt n·ªëi\n",
    "URI = \"neo4j+s://403c0411.databases.neo4j.io\"\n",
    "AUTH = (\"neo4j\", \"20qU7hUdIdlzyXii3tmnCDgvAFkUh-NobhE52Oq7Dvw\")\n",
    "\n",
    "def wipe_everything():\n",
    "    print(\"üöÄ B·∫Øt ƒë·∫ßu quy tr√¨nh x√≥a s·ªï to√†n b·ªô d·ªØ li·ªáu...\")\n",
    "    driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        # 1. X√≥a to√†n b·ªô Constraints (R√†ng bu·ªôc)\n",
    "        print(\"   - ƒêang t√¨m v√† x√≥a Constraints...\")\n",
    "        constraints = session.run(\"SHOW CONSTRAINTS YIELD name\")\n",
    "        for record in constraints:\n",
    "            name = record[\"name\"]\n",
    "            try:\n",
    "                session.run(f\"DROP CONSTRAINT {name}\")\n",
    "                print(f\"     Deleted constraint: {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"     Skipped/Error {name}: {e}\")\n",
    "\n",
    "        # 2. X√≥a to√†n b·ªô Indexes (Ch·ªâ m·ª•c)\n",
    "        print(\"   - ƒêang t√¨m v√† x√≥a Indexes...\")\n",
    "        indexes = session.run(\"SHOW INDEXES YIELD name, type WHERE type <> 'LOOKUP'\") \n",
    "        # LOOKUP index l√† m·∫∑c ƒë·ªãnh c·ªßa h·ªá th·ªëng, kh√¥ng x√≥a ƒë∆∞·ª£c v√† kh√¥ng n√™n x√≥a\n",
    "        for record in indexes:\n",
    "            name = record[\"name\"]\n",
    "            try:\n",
    "                session.run(f\"DROP INDEX {name}\")\n",
    "                print(f\"     Deleted index: {name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"     Skipped/Error {name}: {e}\")\n",
    "\n",
    "        # 3. X√≥a s·∫°ch Node v√† Relationship (D·ªØ li·ªáu)\n",
    "        print(\"   - ƒêang x√≥a s·∫°ch Node v√† Relationship...\")\n",
    "        # V·ªõi 5000 node, l·ªánh n√†y ch·∫°y v√®o c√°i l√† xong, kh√¥ng c·∫ßn chia batch\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        \n",
    "    driver.close()\n",
    "    print(\"‚ú® XONG! Database gi·ªù tr·∫Øng tr∆°n nh∆∞ t·ªù gi·∫•y.\")\n",
    "\n",
    "def verify_empty():\n",
    "    driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (n) RETURN count(n) AS count\")\n",
    "        count = result.single()[\"count\"]\n",
    "        print(f\"üîç Ki·ªÉm tra l·∫°i: S·ªë l∆∞·ª£ng node hi·ªán t·∫°i l√†: {count}\")\n",
    "    driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wipe_everything()\n",
    "    verify_empty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec62628",
   "metadata": {},
   "source": [
    "## Push data bus l√™n neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a692a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U N·∫†P D·ªÆ LI·ªÜU T·ª™ '../data/hcm_bus_final.json'...\n",
      "üßπ ƒêang x√≥a s·∫°ch d·ªØ li·ªáu c≈© (Reset)...\n",
      "‚öôÔ∏è ƒêang t·∫°o Index t·ªëi ∆∞u...\n",
      "üìç ƒêang t·∫°o 5062 Tr·∫°m d·ª´ng...\n",
      "üöå ƒêang x·ª≠ l√Ω 162 Tuy·∫øn xe...\n",
      "\n",
      "‚úÖ TH√ÄNH C√îNG! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·∫°p chu·∫©n ch·ªânh.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from neo4j import GraphDatabase\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "URI = \"neo4j+s://403c0411.databases.neo4j.io\"\n",
    "AUTH = (\"neo4j\", \"20qU7hUdIdlzyXii3tmnCDgvAFkUh-NobhE52Oq7Dvw\") \n",
    "INPUT_FILE = \"../data/hcm_bus_final.json\"\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"T√≠nh kho·∫£ng c√°ch gi·ªØa 2 t·ªça ƒë·ªô (km)\"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 \n",
    "    return c * r\n",
    "\n",
    "def import_data():\n",
    "    print(f\"üöÄ B·∫ÆT ƒê·∫¶U N·∫†P D·ªÆ LI·ªÜU T·ª™ '{INPUT_FILE}'...\")\n",
    "    \n",
    "    # 1. ƒê·ªçc file JSON\n",
    "    try:\n",
    "        with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'. H√£y ki·ªÉm tra l·∫°i t√™n file.\")\n",
    "        return\n",
    "\n",
    "    routes = data['Routes']\n",
    "    stops = data['UniqueStops']\n",
    "    \n",
    "    # Cache t·ªça ƒë·ªô ƒë·ªÉ t√≠nh to√°n nhanh\n",
    "    stop_coords_map = {s['StopId']: {'lat': s['Lat'], 'lng': s['Lng']} for s in stops}\n",
    "\n",
    "    driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        # --- B∆Ø·ªöC 1: X√ìA S·∫†CH S·∫º DB C≈® ---\n",
    "        print(\"üßπ ƒêang x√≥a s·∫°ch d·ªØ li·ªáu c≈© (Reset)...\")\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        \n",
    "        # --- B∆Ø·ªöC 2: T·∫†O INDEX (ƒê·ªÇ T√åM KI·∫æM NHANH) ---\n",
    "        print(\"‚öôÔ∏è ƒêang t·∫°o Index t·ªëi ∆∞u...\")\n",
    "        session.run(\"CREATE INDEX stop_id_idx IF NOT EXISTS FOR (s:BusStop) ON (s.id)\")\n",
    "        session.run(\"CREATE INDEX stop_name_idx IF NOT EXISTS FOR (s:BusStop) ON (s.name)\")\n",
    "        # T·∫°o Fulltext Index cho t√≠nh nƒÉng t√¨m ki·∫øm th√¥ng minh\n",
    "        session.run(\"CREATE FULLTEXT INDEX stopNameIndex IF NOT EXISTS FOR (n:BusStop) ON EACH [n.name, n.code, n.search]\")\n",
    "\n",
    "        # --- B∆Ø·ªöC 3: N·∫†P TR·∫†M (NODES) ---\n",
    "        print(f\"üìç ƒêang t·∫°o {len(stops)} Tr·∫°m d·ª´ng...\")\n",
    "        batch_size = 2000\n",
    "        for i in range(0, len(stops), batch_size):\n",
    "            batch = stops[i:i+batch_size]\n",
    "            session.run(\"\"\"\n",
    "            UNWIND $batch AS s\n",
    "            CREATE (n:BusStop {\n",
    "                id: s.StopId,\n",
    "                name: s.Name,\n",
    "                code: s.Code,\n",
    "                lat: s.Lat, \n",
    "                lng: s.Lng,\n",
    "                search: s.Search,\n",
    "                street: s.Street\n",
    "            })\n",
    "            \"\"\", batch=batch)\n",
    "\n",
    "        # --- B∆Ø·ªöC 4: N·∫†P TUY·∫æN & QUAN H·ªÜ (PH·∫¶N QUAN TR·ªåNG NH·∫§T) ---\n",
    "        print(f\"üöå ƒêang x·ª≠ l√Ω {len(routes)} Tuy·∫øn xe...\")\n",
    "        \n",
    "        edges_batch = [] \n",
    "        \n",
    "        for r in routes:\n",
    "            # T·∫°o Node Tuy·∫øn Xe\n",
    "            display_name = f\"Bus {r['RouteNo']}: {r['RouteName']}\"\n",
    "            price_clean = r['Tickets'].replace(\"<br/>\", \"\\n\").replace(\"&nbsp\", \" \") if r['Tickets'] else \"\"\n",
    "            \n",
    "            session.run(\"\"\"\n",
    "            MERGE (r:BusRoute {id: $rid})\n",
    "            SET r.route_no = $rno, r.name = $display, r.price = $price\n",
    "            \"\"\", rid=r['RouteId'], rno=r['RouteNo'], display=display_name, price=price_clean)\n",
    "\n",
    "            route_stops = r['Stops']\n",
    "            if not route_stops: continue\n",
    "\n",
    "            # A. N·ªëi Tr·∫°m v√†o Tuy·∫øn (ON_ROUTE) - FIX L·ªñI GHI ƒê√à\n",
    "            # Quan tr·ªçng: Th√™m {direction: ...} v√†o trong MERGE ƒë·ªÉ t√°ch bi·ªát chi·ªÅu ƒëi/v·ªÅ\n",
    "            session.run(\"\"\"\n",
    "            UNWIND $stops AS s\n",
    "            MATCH (r:BusRoute {id: $rid})\n",
    "            MATCH (st:BusStop {id: s.StopId})\n",
    "            MERGE (st)-[rel:ON_ROUTE {direction: s.Direction}]->(r)\n",
    "            SET rel.order = s.Order\n",
    "            \"\"\", stops=route_stops, rid=r['RouteId'])\n",
    "\n",
    "            # B. N·ªëi Tr·∫°m v·ªõi Tr·∫°m (NEXT_HOP) - ƒê·ªÉ v·∫Ω ƒë∆∞·ªùng ƒëi\n",
    "            for i in range(len(route_stops) - 1):\n",
    "                curr = route_stops[i]\n",
    "                next_s = route_stops[i+1]\n",
    "                \n",
    "                # Ch·ªâ n·ªëi n·∫øu c√πng m·ªôt chi·ªÅu (Direction gi·ªëng nhau)\n",
    "                if curr['Direction'] == next_s['Direction']:\n",
    "                    c_id = curr['StopId']\n",
    "                    n_id = next_s['StopId']\n",
    "                    \n",
    "                    if c_id in stop_coords_map and n_id in stop_coords_map:\n",
    "                        c_coords = stop_coords_map[c_id]\n",
    "                        n_coords = stop_coords_map[n_id]\n",
    "                        \n",
    "                        dist_km = haversine(c_coords['lng'], c_coords['lat'], n_coords['lng'], n_coords['lat'])\n",
    "                        time_min = (dist_km / 30) * 60 # Gi·∫£ s·ª≠ t·ªëc ƒë·ªô 30km/h\n",
    "                        if time_min < 0.5: time_min = 0.5\n",
    "                        \n",
    "                        edges_batch.append({\n",
    "                            \"from_id\": c_id, \"to_id\": n_id, \"route_id\": r['RouteId'],\n",
    "                            \"dist\": dist_km, \"time\": time_min,\n",
    "                            \"direction\": curr['Direction'] # L∆∞u lu√¥n chi·ªÅu v√†o c·∫°nh n·ªëi\n",
    "                        })\n",
    "\n",
    "            # N·∫°p Batch NEXT_HOP\n",
    "            if len(edges_batch) >= 2000:\n",
    "                session.run(\"\"\"\n",
    "                UNWIND $edges AS e\n",
    "                MATCH (a:BusStop {id: e.from_id})\n",
    "                MATCH (b:BusStop {id: e.to_id})\n",
    "                MERGE (a)-[r:NEXT_HOP {route_id: e.route_id, direction: e.direction}]->(b)\n",
    "                SET r.dist = e.dist, r.time = e.time\n",
    "                \"\"\", edges=edges_batch)\n",
    "                edges_batch = []\n",
    "        \n",
    "        # N·∫°p n·ªët s·ªë d∆∞\n",
    "        if edges_batch:\n",
    "            session.run(\"\"\"\n",
    "            UNWIND $edges AS e\n",
    "            MATCH (a:BusStop {id: e.from_id})\n",
    "            MATCH (b:BusStop {id: e.to_id})\n",
    "            MERGE (a)-[r:NEXT_HOP {route_id: e.route_id, direction: e.direction}]->(b)\n",
    "            SET r.dist = e.dist, r.time = e.time\n",
    "            \"\"\", edges=edges_batch)\n",
    "\n",
    "    driver.close()\n",
    "    print(\"\\n‚úÖ TH√ÄNH C√îNG! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·∫°p chu·∫©n ch·ªânh.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba07ac28",
   "metadata": {},
   "source": [
    "## Push data vƒÉn h√≥a du l·ªãch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1cdf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: ../data/VanHoaVaDuLichVN_Full_Img.json\n",
      "üîπ T√¨m th·∫•y 6 m·ª•c General Information.\n",
      "üî∏ T√¨m th·∫•y 63 T·ªânh/Th√†nh.\n",
      "üìä T·ªïng s·ªë l∆∞·ª£ng Node c·∫ßn n·∫°p: 1478\n",
      "‚öôÔ∏è  ƒêang c·∫•u h√¨nh Constraints (R√†ng bu·ªôc d·ªØ li·ªáu)...\n",
      "   ‚úÖ ƒê√£ th·ª±c thi: CREATE CONSTRAINT FOR (c:Country) REQUIRE c.id IS UNIQUE\n",
      "   ‚úÖ ƒê√£ th·ª±c thi: CREATE CONSTRAINT FOR (p:Province) REQUIRE p.id IS UNIQUE\n",
      "   ‚úÖ ƒê√£ th·ª±c thi: CREATE CONSTRAINT FOR (n:Searchable) REQUIRE n.id IS UNIQUE\n",
      "   ‚úÖ ƒê√£ th·ª±c thi: CREATE CONSTRAINT FOR (g:GeneralInfo) REQUIRE g.id IS UNIQUE\n",
      "‚è≥ ƒêang n·∫°p General Info (Qu·ªëc gia)...\n",
      "‚è≥ ƒêang n·∫°p 1472 ƒë·ªãa ƒëi·ªÉm thu·ªôc c√°c T·ªânh...\n",
      "   ‚úÖ Batch 0 -> 500 OK\n",
      "   ‚úÖ Batch 500 -> 1000 OK\n",
      "   ‚úÖ Batch 1000 -> 1472 OK\n",
      "‚è±Ô∏è Th·ªùi gian n·∫°p Provinces: 1.53 gi√¢y\n",
      "üéâ HO√ÄN T·∫§T TO√ÄN B·ªò! D·ªØ li·ªáu ƒë√£ l√™n Neo4j th√†nh c√¥ng.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "from neo4j import GraphDatabase\n",
    "from datetime import datetime\n",
    "\n",
    "# ================= C·∫§U H√åNH =================\n",
    "# L∆∞u √Ω: ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n file ch√≠nh x√°c so v·ªõi v·ªã tr√≠ file code c·ªßa b·∫°n\n",
    "URI = \"neo4j+s://403c0411.databases.neo4j.io\"\n",
    "AUTH = (\"neo4j\", \"20qU7hUdIdlzyXii3tmnCDgvAFkUh-NobhE52Oq7Dvw\")\n",
    "JSON_PATH = \"../data/VanHoaVaDuLichVN_Full_Img.json\" \n",
    "\n",
    "# Mapping Label (Chu·∫©n h√≥a t√™n Label trong Neo4j)\n",
    "LABEL_MAP = {\n",
    "    \"Place\": \"TouristDestination\",\n",
    "    \"Festival\": \"CulturalEvent\",\n",
    "    \"Religious\": \"SpiritualSite\",\n",
    "    \"Nature\": \"NaturalLandscape\",\n",
    "    \"GeneralTopic\": \"GeneralInfo\",\n",
    "    \"Cuisine\": \"Culinary\"\n",
    "}\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"L√†m s·∫°ch d·ªØ li·ªáu text, x·ª≠ l√Ω null\"\"\"\n",
    "    return str(text).strip() if text else \"\"\n",
    "\n",
    "def generate_spot_id(parent_code, item_name):\n",
    "    \"\"\"T·∫°o ID duy nh·∫•t: PARENT_CODE + ITEM_NAME\"\"\"\n",
    "    p_code = clean_text(parent_code).replace(\"_\", \"\").upper()\n",
    "    n_clean = re.sub(r'[^\\w]', '', clean_text(item_name).upper())\n",
    "    return f\"SPOT_{p_code}_{n_clean}\"\n",
    "\n",
    "def setup_constraints(session):\n",
    "    \"\"\"\n",
    "    T·∫°o Constraint Unique. \n",
    "    S·ª≠ d·ª•ng try-except ƒë·ªÉ b·ªè qua l·ªói n·∫øu Constraint ƒë√£ t·ªìn t·∫°i (Fix l·ªói IF NOT EXISTS)\n",
    "    \"\"\"\n",
    "    print(\"‚öôÔ∏è  ƒêang c·∫•u h√¨nh Constraints (R√†ng bu·ªôc d·ªØ li·ªáu)...\")\n",
    "    \n",
    "    # Danh s√°ch c√°c l·ªánh t·∫°o constraint chu·∫©n cho Neo4j 5.x/Aura\n",
    "    constraints = [\n",
    "        \"CREATE CONSTRAINT FOR (c:Country) REQUIRE c.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT FOR (p:Province) REQUIRE p.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT FOR (n:Searchable) REQUIRE n.id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT FOR (g:GeneralInfo) REQUIRE g.id IS UNIQUE\"\n",
    "    ]\n",
    "\n",
    "    for query in constraints:\n",
    "        try:\n",
    "            session.run(query)\n",
    "            print(f\"   ‚úÖ ƒê√£ th·ª±c thi: {query}\")\n",
    "        except Exception as e:\n",
    "            # N·∫øu l·ªói ch·ª©a \"already exists\" th√¨ b·ªè qua, c√≤n l·ªói kh√°c th√¨ in ra c·∫£nh b√°o\n",
    "            error_msg = str(e).lower()\n",
    "            if \"already exists\" in error_msg or \"equivalent constraint\" in error_msg:\n",
    "                pass \n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è C·∫£nh b√°o (c√≥ th·ªÉ b·ªè qua n·∫øu ƒë√£ c√≥): {e}\")\n",
    "\n",
    "# --- H√ÄM 1: IMPORT GENERAL INFO (C·∫§P QU·ªêC GIA) ---\n",
    "def import_general_info(tx, batch_data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $batch AS row\n",
    "    \n",
    "    // 1. T·∫°o Node QU·ªêC GIA (Country) - Ch·ªâ c√≥ 1 node duy nh·∫•t\n",
    "    MERGE (c:Country {id: \"VN\"})\n",
    "    SET c.name = \"VIETNAM\",\n",
    "        c.type = \"National\",\n",
    "        c.last_updated = datetime()\n",
    "    \n",
    "    // 2. T·∫°o Node th√¥ng tin chung\n",
    "    MERGE (n:GeneralInfo {id: row.id})\n",
    "    SET n.name = row.name,\n",
    "        n.original_type = row.original_type,\n",
    "        n.content = row.content,\n",
    "        n.embedding_text = row.embedding_text, // Gi·ªØ nguy√™n g·ªëc\n",
    "        n.image_path = row.image_path,\n",
    "        n.last_updated = datetime()\n",
    "    \n",
    "    // 3. N·ªëi quan h·ªá: GeneralInfo -> THU·ªòC V·ªÄ -> Country\n",
    "    MERGE (n)-[:BELONGS_TO]->(c)\n",
    "    \"\"\"\n",
    "    tx.run(query, batch=batch_data)\n",
    "\n",
    "# --- H√ÄM 2: IMPORT PROVINCES (C·∫§P T·ªàNH) ---\n",
    "def import_provinces(tx, batch_data):\n",
    "    query = \"\"\"\n",
    "    UNWIND $batch AS row\n",
    "    \n",
    "    MERGE (p:Province {id: row.province_id})\n",
    "    SET p.name = row.province_name,\n",
    "        p.last_updated = datetime()\n",
    "    \n",
    "    MERGE (n:Searchable {id: row.id})\n",
    "    SET n.name = row.name,\n",
    "        n.province_name = row.province_name,\n",
    "        n.original_type = row.original_type,\n",
    "        n.content = row.content,\n",
    "        n.embedding_text = row.embedding_text,\n",
    "        n.image_path = row.image_path,\n",
    "        n.last_updated = datetime()\n",
    "\n",
    "    WITH n, p, row\n",
    "    CALL apoc.create.addLabels(n, [row.neo4j_label]) YIELD node\n",
    "    \n",
    "    MERGE (n)-[:LOCATED_IN]->(p)\n",
    "    \"\"\"\n",
    "    tx.run(query, batch=batch_data)\n",
    "\n",
    "def main():\n",
    "    driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "    print(f\"üöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {JSON_PATH}\")\n",
    "\n",
    "    # --- 1. ƒê·ªåC FILE JSON ---\n",
    "    try:\n",
    "        with open(JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i '{JSON_PATH}'. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói ƒë·ªçc file: {e}\")\n",
    "        return\n",
    "\n",
    "    # --- 2. CHU·∫®N B·ªä D·ªÆ LI·ªÜU ---\n",
    "    \n",
    "    # A. D·ªØ li·ªáu General Information\n",
    "    general_infos = data.get(\"General_Information\", [])\n",
    "    print(f\"üîπ T√¨m th·∫•y {len(general_infos)} m·ª•c General Information.\")\n",
    "    \n",
    "    gen_nodes = []\n",
    "    for item in general_infos:\n",
    "        raw_type = item.get(\"type\", \"GeneralTopic\")\n",
    "        gen_nodes.append({\n",
    "            \"id\": generate_spot_id(\"VN\", item.get(\"name\")),\n",
    "            \"name\": item.get(\"name\"),\n",
    "            \"original_type\": raw_type,\n",
    "            \"content\": clean_text(item.get(\"content\")),\n",
    "            \"embedding_text\": clean_text(item.get(\"embedding_text\")),\n",
    "            \"image_path\": clean_text(item.get(\"image_path\"))\n",
    "        })\n",
    "\n",
    "    # B. D·ªØ li·ªáu Provinces\n",
    "    provinces = data.get(\"Provinces\", [])\n",
    "    print(f\"üî∏ T√¨m th·∫•y {len(provinces)} T·ªânh/Th√†nh.\")\n",
    "    \n",
    "    prov_nodes = []\n",
    "    for province in provinces:\n",
    "        p_id = province.get(\"id\")     # VD: P_000\n",
    "        p_name = province.get(\"name\") # VD: H√Ä N·ªòI\n",
    "        items = province.get(\"items\", [])\n",
    "        \n",
    "        for item in items:\n",
    "            raw_type = item.get(\"type\", \"Place\")\n",
    "            item_name = item.get(\"name\", \"Unknown\")\n",
    "            \n",
    "            prov_nodes.append({\n",
    "                \"id\": generate_spot_id(p_id, item_name),\n",
    "                \"name\": item_name,\n",
    "                \"province_id\": p_id,\n",
    "                \"province_name\": p_name,\n",
    "                \"original_type\": raw_type,\n",
    "                \"neo4j_label\": LABEL_MAP.get(raw_type, \"TouristDestination\"),\n",
    "                \"content\": clean_text(item.get(\"content\")),\n",
    "                \"embedding_text\": clean_text(item.get(\"embedding_text\")),\n",
    "                \"image_path\": clean_text(item.get(\"image_path\"))\n",
    "            })\n",
    "\n",
    "    total_nodes = len(gen_nodes) + len(prov_nodes)\n",
    "    print(f\"üìä T·ªïng s·ªë l∆∞·ª£ng Node c·∫ßn n·∫°p: {total_nodes}\")\n",
    "\n",
    "    # --- 3. TH·ª∞C THI TR√äN NEO4J ---\n",
    "    if total_nodes > 0:\n",
    "        with driver.session() as session:\n",
    "            # B∆∞·ªõc 1: Setup Constraints (ƒê√£ fix l·ªói c√∫ ph√°p)\n",
    "            setup_constraints(session)\n",
    "            \n",
    "            # B∆∞·ªõc 2: N·∫°p General Info\n",
    "            if gen_nodes:\n",
    "                print(\"‚è≥ ƒêang n·∫°p General Info (Qu·ªëc gia)...\")\n",
    "                try:\n",
    "                    session.execute_write(import_general_info, gen_nodes)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå L·ªói khi n·∫°p General Info: {e}\")\n",
    "\n",
    "            # B∆∞·ªõc 3: N·∫°p Provinces (Batching)\n",
    "            if prov_nodes:\n",
    "                batch_size = 500\n",
    "                total = len(prov_nodes)\n",
    "                print(f\"‚è≥ ƒêang n·∫°p {total} ƒë·ªãa ƒëi·ªÉm thu·ªôc c√°c T·ªânh...\")\n",
    "                \n",
    "                start_time = time.time()\n",
    "                for i in range(0, total, batch_size):\n",
    "                    batch = prov_nodes[i : i + batch_size]\n",
    "                    try:\n",
    "                        session.execute_write(import_provinces, batch)\n",
    "                        print(f\"   ‚úÖ Batch {i} -> {min(i+batch_size, total)} OK\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ùå L·ªói t·∫°i batch {i}: {e}\")\n",
    "                \n",
    "                duration = time.time() - start_time\n",
    "                print(f\"‚è±Ô∏è Th·ªùi gian n·∫°p Provinces: {duration:.2f} gi√¢y\")\n",
    "\n",
    "    driver.close()\n",
    "    print(\"üéâ HO√ÄN T·∫§T TO√ÄN B·ªò! D·ªØ li·ªáu ƒë√£ l√™n Neo4j th√†nh c√¥ng.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
