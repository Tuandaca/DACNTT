import os
import logging
import asyncio
import unicodedata
import io
import json
import time
import re
from typing import Optional, Union, List
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from neo4j import AsyncGraphDatabase
import google.generativeai as genai
from PIL import Image

from bus_core import BusBotV13

# --- 1. C·∫§U H√åNH LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger(__name__)

# --- 2. LOAD BI·∫æN M√îI TR∆Ø·ªúNG ---
load_dotenv(override=True)

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j") 
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

# --- 3. KH·ªûI T·∫†O MODEL & DB ---
if not GEMINI_API_KEY:
    logger.error("‚ùå CH∆ØA C√ì GEMINI_API_KEY TRONG FILE .ENV")

genai.configure(api_key=GEMINI_API_KEY)
llm_model = genai.GenerativeModel('gemini-2.0-flash') 

logger.info("SYSTEM: Loading Vector Model...")
model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")
logger.info("SYSTEM: Vector Model Loaded.")

tourism_driver = AsyncGraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
logger.info("SYSTEM: Initializing BusBot...")
bus_bot = BusBotV13()
logger.info("SYSTEM: BusBot Ready.")

# --- [CRITICAL FIX] H√ÄM CHU·∫®N H√ìA AN TO√ÄN ---
def normalize_text(text: Union[str, List[str], None]) -> str:
    """
    Chu·∫©n h√≥a text ƒë·∫ßu v√†o, x·ª≠ l√Ω c·∫£ tr∆∞·ªùng h·ª£p text b·ªã truy·ªÅn v√†o l√† List
    ƒë·ªÉ tr√°nh l·ªói AttributeError: 'list' object has no attribute 'replace'
    """
    if text is None: return ""
    if isinstance(text, list):
        # N·∫øu l√† list, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n ho·∫∑c join l·∫°i t√πy ng·ªØ c·∫£nh.
        # ·ªû ƒë√¢y ta l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n non-empty l√†m ƒë·∫°i di·ªán
        text = next((t for t in text if t), "")
    
    if not isinstance(text, str):
        text = str(text)

    return unicodedata.normalize('NFC', text).lower().strip()

# --- [FIXED V4] H√ÄM L√ÄM S·∫†CH C√ì ƒêI·ªÄU KI·ªÜN ---
def clean_entity_name(raw_text: str, use_alias: bool = False) -> str:
    if not raw_text: return ""
    
    cleaned = raw_text.lower().strip()
    
    # 1. C·∫ÆT PREFIX (Gi·ªØ nguy√™n)
    prefixes = [
        "l·ªô tr√¨nh ƒëi xe bu√Ωt t·ª´", "l·ªô tr√¨nh xe bu√Ωt ƒëi t·ª´", "l·ªô tr√¨nh xe bu√Ωt t·ª´", 
        "l·ªô tr√¨nh ƒëi t·ª´", "l·ªô tr√¨nh t·ª´", "l·ªô tr√¨nh xe bu√Ωt v·ªÅ", "l·ªô tr√¨nh",
        "h∆∞·ªõng d·∫´n b·∫Øt xe bu√Ωt t·ª´", "h∆∞·ªõng d·∫´n ƒëi xe bu√Ωt t·ª´", "h∆∞·ªõng d·∫´n ƒë√≥n xe bu√Ωt t·ª´",
        "h∆∞·ªõng d·∫´n b·∫Øt xe t·ª´", "h∆∞·ªõng d·∫´n ƒëi t·ª´", "h∆∞·ªõng d·∫´n ƒë∆∞·ªùng ƒëi t·ª´", "h∆∞·ªõng d·∫´n",
        "c√°ch ƒëi xe bu√Ωt t·ª´", "c√°ch b·∫Øt xe bu√Ωt t·ª´", "c√°ch ƒëi t·ª´", "t√¨m ƒë∆∞·ªùng ƒëi t·ª´",
        "ƒë∆∞·ªùng ƒëi xe bu√Ωt t·ª´", "ƒë∆∞·ªùng ƒëi t·ª´", "l√†m sao ƒë·ªÉ ƒëi t·ª´", "l√†m sao ƒëi t·ª´",
        "xe bu√Ωt ƒëi t·ª´", "xe bu√Ωt t·ª´", "tuy·∫øn xe t·ª´", "b·∫Øt xe t·ª´", "ƒë√≥n xe t·ª´", "ƒëi xe bu√Ωt t·ª´",
        "ƒëi t·ª´", "ƒë·∫øn", "t·ªõi", "v·ªÅ", "sang", "qua", "t·∫°i", "·ªü", "khu v·ª±c", 
        "t√¨m ƒë∆∞·ªùng", "ch·ªâ ƒë∆∞·ªùng", "cho t√¥i h·ªèi v·ªÅ", "th√¥ng tin v·ªÅ", "gi·ªõi thi·ªáu v·ªÅ", "bi·∫øt g√¨ v·ªÅ"
    ]
    
    for word in prefixes:
        if cleaned.startswith(word):
            cleaned = cleaned.replace(word, "", 1).strip()
            
    # 2. C·∫ÆT SUFFIX (Gi·ªØ nguy√™n)
    suffixes = [
        " nh∆∞ th·∫ø n√†o", " th·∫ø n√†o", " ra sao", " l√†m sao", 
        " b·∫±ng c√°ch n√†o", " ƒëi ƒë∆∞·ªùng n√†o",
        " ƒë∆∞·ª£c kh√¥ng", " c√≥ ƒë∆∞·ª£c kh√¥ng", " kh√¥ng ·∫°", " kh√¥ng",
        " s·ªë m·∫•y", " bao nhi√™u", " m·∫•t bao l√¢u",
        " ·ªü ƒë√¢u", " ch·ªó n√†o",
        " nh√©", " nha", " nh·ªâ", " v·∫≠y", " ·∫°", " h·∫£", " h·ª≠"
    ]
    
    for suffix in suffixes:
        if cleaned.endswith(suffix):
            cleaned = cleaned[:-len(suffix)].strip()

    # 3. Double Check t·ª´ n·ªëi
    secondary_stopwords = ["t·ª´ ", "ƒë·∫øn ", "v·ªÅ ", "t·ªõi ", "sang ", "qua ", "c·ªßa "]
    for sw in secondary_stopwords:
        if cleaned.startswith(sw.strip()):
            cleaned = cleaned.replace(sw.strip(), "", 1).strip()

    # --- [CH·ªà √ÅP D·ª§NG KHI L√Ä TOURISM] ---
    if use_alias:
        ENTITY_ALIASES = {
            "dinh ƒë·ªôc l·∫≠p": "h·ªôi tr∆∞·ªùng th·ªëng nh·∫•t",
            "dinh norodom": "h·ªôi tr∆∞·ªùng th·ªëng nh·∫•t",
            "ph·ªß ƒë·∫ßu r·ªìng": "h·ªôi tr∆∞·ªùng th·ªëng nh·∫•t",
            
            "nh√† th·ªù ƒë·ª©c b√†": "v∆∞∆°ng cung th√°nh ƒë∆∞·ªùng ch√≠nh t√≤a ƒë·ª©c b√† s√†i g√≤n",
            "nh√† th·ªù l·ªõn s√†i g√≤n": "v∆∞∆°ng cung th√°nh ƒë∆∞·ªùng ch√≠nh t√≤a ƒë·ª©c b√† s√†i g√≤n",
            
            "b∆∞u ƒëi·ªán th√†nh ph·ªë": "b∆∞u ƒëi·ªán trung t√¢m s√†i g√≤n",
            "b∆∞u ƒëi·ªán s√†i g√≤n": "b∆∞u ƒëi·ªán trung t√¢m s√†i g√≤n",
            
            "b·∫øn nh√† r·ªìng": "b·∫£o t√†ng h·ªì ch√≠ minh",
            "b·∫£o t√†ng b·∫øn nh√† r·ªìng": "b·∫£o t√†ng h·ªì ch√≠ minh",
            
            "ch·ª£ l·ªõn": "ch·ª£ b√¨nh t√¢y",
            "landmart 81": "landmark 81",
            "lƒÉng b√°c": "lƒÉng ch·ªß t·ªãch h·ªì ch√≠ minh"
        }
        
        if cleaned in ENTITY_ALIASES:
            return ENTITY_ALIASES[cleaned].title()

    return cleaned.title()

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield
    await tourism_driver.close()
    bus_bot.close()

app = FastAPI(title="Professional Travel & Transport AI", lifespan=lifespan)

if not os.path.exists("images_items"):
    os.makedirs("images_items")
app.mount("/images_items", StaticFiles(directory="images_items"), name="images")

# --- 4. DANH S√ÅCH T·ª™ KH√ìA ---
QUESTION_MARKERS = [
    "?", "l√† g√¨", "c√°i g√¨", "vi·ªác g√¨", "th·ª© g√¨", "ƒëi·ªÅu g√¨",
    "·ªü ƒë√¢u", "ch·ªó n√†o", "n∆°i n√†o", "khu n√†o", "ƒë√¢u",
    "khi n√†o", "l√∫c n√†o", "bao gi·ªù", "h·ªìi n√†o", "ng√†y n√†o",
    "ai", "ng∆∞·ªùi n√†o", "nh√¢n v·∫≠t n√†o", "v·ªã n√†o",
    "t·∫°i sao", "v√¨ sao", "nguy√™n nh√¢n", "l√Ω do", "sao l·∫°i",
    "th·∫ø n√†o", "ra sao", "nh∆∞ n√†o", "l√†m sao", "c√°ch n√†o",
    "bao nhi√™u", "bao l√¢u", "bao xa", "m·∫•y", "s·ªë l∆∞·ª£ng",
    "c√≥...kh√¥ng", "ƒë∆∞·ª£c kh√¥ng", "c√≥ ph·∫£i", "kh√¥ng ·∫°", "ch∆∞a", "h·∫£", "h·ª≠",
    "cho h·ªèi", "mu·ªën h·ªèi", "t√¨m hi·ªÉu", "ch·ªâ gi√∫p", "h∆∞·ªõng d·∫´n", "t∆∞ v·∫•n",
    "th√¥ng tin", "chi ti·∫øt", "gi·ªõi thi·ªáu", "k·ªÉ v·ªÅ", "n√≥i v·ªÅ", "li·ªát k√™", "danh s√°ch"
]

# --- 5. LOGIC T√åM KI·∫æM TOURISM (ƒê√É FIX CRASH) ---
async def hybrid_search_tourism(text: str, province_filter: Union[str, List[str]] = None):
    # Lu√¥n l√†m s·∫°ch input tr∆∞·ªõc
    text = clean_entity_name(text)
    search_text_norm = normalize_text(text)
    records = []
    
    async with tourism_driver.session() as session:
        # X·ª≠ l√Ω province_filter an to√†n
        p_filter_cypher = ""
        if province_filter:
            # D√πng h√†m normalize_text ƒë√£ fix ·ªü tr√™n ƒë·ªÉ x·ª≠ l√Ω c·∫£ list l·∫´n str
            p_filter_cypher = normalize_text(province_filter)

        # Query 1: Filter theo T·ªânh (∆Øu ti√™n cao)
        if len(p_filter_cypher) > 2:
            cypher_loc = """
            MATCH (node:Searchable)-[:LOCATED_IN]->(p:Province)
            WHERE toLower(p.name) CONTAINS $province_norm
            AND (toLower(node.name) CONTAINS $text_norm OR toLower(node.content) CONTAINS $text_norm)
            RETURN elementId(node) as id, node, 1.5 as score, p.name as province_name, 'location_filter' as source_type
            LIMIT 15
            """
            try:
                r_loc = await session.run(cypher_loc, province_norm=p_filter_cypher, text_norm=search_text_norm)
                records.extend([record.data() async for record in r_loc])
            except Exception as e:
                logger.error(f"Error Loc Search: {e}")

        # Query 2: Vector & Keyword Search (N·∫øu √≠t k·∫øt qu·∫£)
        if len(records) < 5: 
            loop = asyncio.get_running_loop()
            try:
                vector = await loop.run_in_executor(None, lambda: model.encode(text).tolist())
                
                cypher_vector = "CALL db.index.vector.queryNodes('searchable_index', 50, $vector) YIELD node, score OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, score, p.name as province_name, 'vector' as source_type"
                cypher_keyword = "MATCH (node:Searchable) WHERE toLower(node.name) CONTAINS $text_norm OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, 1.0 as score, p.name as province_name, 'keyword' as source_type LIMIT 20"
                
                try:
                    r1 = await session.run(cypher_vector, vector=vector)
                    records.extend([record.data() async for record in r1])
                except: pass
                
                try:
                    r2 = await session.run(cypher_keyword, text_norm=search_text_norm)
                    records.extend([record.data() async for record in r2])
                except: pass
            except Exception as e:
                logger.error(f"Vector Encode Error: {e}")

    # Rerank & Deduplicate
    unique_results = {}
    for r in records:
        uid = r['id']
        
        # Logic gi·∫£m ƒëi·ªÉm n·∫øu sai t·ªânh (ƒê√£ fix l·ªói so s√°nh list)
        if province_filter and r.get('province_name'):
            r_province_norm = normalize_text(r['province_name'])
            is_match = False
            
            # Chu·∫©n h√≥a filter ƒë·∫ßu v√†o th√†nh list ƒë·ªÉ d·ªÖ so s√°nh
            filter_list = province_filter if isinstance(province_filter, list) else [province_filter]
            
            for p in filter_list:
                if normalize_text(p) in r_province_norm:
                    is_match = True
                    break
            
            if not is_match:
                r['score'] = r['score'] * 0.1
        
        if r['source_type'] == 'vector' and r['score'] < 0.65: continue
        
        if uid not in unique_results:
            unique_results[uid] = r
            if r['source_type'] == 'location_filter':
                unique_results[uid]['score'] = 10.0
            else:
                unique_results[uid]['score'] = 10.0 if r['source_type'] == 'keyword' else r['score']
    
    sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
    return sorted_results[:10]

# --- [CRITICAL FIX] PROMPT B·∫¢O V·ªÜ CH·ªêNG LEAK ---
async def fallback_general_knowledge(question: str):
    system_prompt = f"""
    VAI TR√í: B·∫°n l√† Tr·ª£ l√Ω ·∫£o chuy√™n v·ªÅ Du l·ªãch & VƒÉn h√≥a Vi·ªát Nam.
    
    DANH S√ÅCH C·∫§M (TUY·ªÜT ƒê·ªêI KH√îNG TR·∫¢ L·ªúI):
    1. L·∫¨P TR√åNH: Code, Python, Java, C++, SQL, Docker, Fix bug, L·ªói ph·∫ßn m·ªÅm.
    2. T√ÄI CH√çNH: L√£i su·∫•t, Ng√¢n h√†ng, Ch·ª©ng kho√°n, Ti·ªÅn ·∫£o, Vay v·ªën, ƒê·∫•t n·ªÅn.
    3. Y T·∫æ: Ch·ªØa b·ªánh, Thu·ªëc, B√°c sƒ©, Tri·ªáu ch·ª©ng, ƒêau nh·ª©c.
    4. GIAO TH√îNG LI√äN T·ªàNH: M√°y bay, T√†u h·ªèa (tr·ª´ khi h·ªèi ga t√†u t·∫°i TP.HCM), Xe kh√°ch ƒëi t·ªânh.
       
    H√ÄNH ƒê·ªòNG B·∫ÆT BU·ªòC KHI G·∫∂P CH·ª¶ ƒê·ªÄ C·∫§M:
    - Tr·∫£ l·ªùi: "Xin l·ªói, t√¥i ch·ªâ l√† tr·ª£ l√Ω du l·ªãch v√† kh√¥ng c√≥ chuy√™n m√¥n v·ªÅ lƒ©nh v·ª±c n√†y. Vui l√≤ng tham kh·∫£o √Ω ki·∫øn chuy√™n gia."
    - KH√îNG gi·∫£i th√≠ch th√™m, KH√îNG ƒë∆∞a ra l·ªùi khuy√™n "s∆° s∆°".
    - KH√îNG y√™u c·∫ßu g·ª≠i ·∫£nh.
    
    C√ÇU H·ªéI: "{question}"
    TR·∫¢ L·ªúI NG·∫ÆN G·ªåN:
    """
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: llm_model.generate_content(system_prompt))
    return response.text

class ChatRequest(BaseModel):
    question: str
    province: Optional[Union[str, List[str]]] = None # Cho ph√©p c·∫£ List v√† String

# ==========================================
#               MAIN CHAT API
# ==========================================
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()
    raw_question = request.question.strip()
    question = re.sub(r'[\\/*.,?]+$', '', raw_question).strip()
    
    logger.info(f"REQ: {question}")
    lower_q = question.lower()
    
    # --- NH·∫¨N DI·ªÜN INTENT TH√îNG MINH ---
    is_bus_intent = False
    
    # Danh s√°ch t·ª´ kh√≥a Du l·ªãch/Ngo·∫°i t·ªânh (∆Øu ti√™n cao h∆°n Bus)
    tourism_keywords = [
        "l·∫≠p k·∫ø ho·∫°ch", "k·∫ø ho·∫°ch", "l·ªãch tr√¨nh", "ƒëi ch∆°i", "du l·ªãch", "tham quan", 
        "tour", "m√°y bay", "kh√°ch s·∫°n", "nh√† h√†ng", "ƒÉn g√¨", "ch∆°i g√¨", 
        "t√†u h·ªèa", "t√†u cao t·ªëc", "xe kh√°ch", "limousine",
        "h√† n·ªôi", "ƒë√† n·∫µng", "hu·∫ø", "ƒë√† l·∫°t", "ph√∫ qu·ªëc", "nha trang", "c√¥n ƒë·∫£o", "quy nh∆°n", "sapa"
    ]
    
    is_tourism_override = any(k in lower_q for k in tourism_keywords)

    if not is_tourism_override:
        dest_markers = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "] 
        strong_bus_words = ["xe bus", "xe bu√Ωt", "bu√Ωt", "tuy·∫øn xe", "tr·∫°m xe", "s·ªë m·∫•y", "metro", "t√†u ƒëi·ªán"]
        
        if any(w in lower_q for w in strong_bus_words):
            is_bus_intent = True
        elif any(m.strip() in lower_q for m in dest_markers) and \
             any(w in lower_q for w in ["t·ª´", "ƒëi", "ƒë∆∞·ªùng", "c√°ch", "l·ªô tr√¨nh", "ch·ªâ ƒë∆∞·ªùng"]):
            is_bus_intent = True

    # Prompt Router ph√¢n lo·∫°i
    router_prompt = f"""
    Ph√¢n t√≠ch c√¢u h·ªèi: "{question}".
    Nhi·ªám v·ª•:
    1. Intent: 
       - "bus": Ch·ªâ h·ªèi v·ªÅ xe bu√Ωt/metro n·ªôi th√†nh TP.HCM.
       - "tourism": H·ªèi v·ªÅ du l·ªãch, vƒÉn h√≥a, ƒë·ªãa danh Vi·ªát Nam.
       - "greeting": Ch√†o h·ªèi x√£ giao.
       - "ood": T·∫•t c·∫£ ch·ªß ƒë·ªÅ kh√°c (Y t·∫ø, IT, T√†i ch√≠nh, B·∫•t ƒë·ªông s·∫£n, Giao th√¥ng li√™n t·ªânh).
       
    2. Location: Tr√≠ch xu·∫•t t√™n ƒë·ªãa danh (N·∫æU C√ì).
    3. Mode: "list" | "detail".
    JSON Output: {{ "intent": "...", "location": "...", "mode": "..." }}
    """
    
    intent = "bus" if is_bus_intent else "tourism"
    location_filter = None
    mode = "detail"

    try:
        if not is_bus_intent: 
            res = await asyncio.to_thread(llm_model.generate_content, router_prompt)
            clean = res.text.strip().replace("```json", "").replace("```", "")
            parsed = json.loads(clean)
            intent = parsed.get("intent", "tourism")
            location_filter = parsed.get("location")
            mode = parsed.get("mode", "detail")
    except: pass

    # Override n·∫øu Router sai
    if intent == "bus" and is_tourism_override:
        intent = "tourism"
    
    has_question_word = any(marker in lower_q for marker in QUESTION_MARKERS)
    if intent != "bus":
        if has_question_word and intent == "greeting":
            intent = "tourism"
        elif not has_question_word:
            greeting_words = ["xin ch√†o", "hello", "hi bot", "ch√†o b·∫°n", "alo"]
            if any(w == lower_q or lower_q.startswith(w) for w in greeting_words) and len(lower_q) < 20:
                intent = "greeting"

    # [FIX] Clean location t·ª´ Router lu√¥n cho ch·∫Øc
    if location_filter:
        location_filter = clean_entity_name(str(location_filter))

    logger.info(f"üîç INTENT: {intent} | LOC: {location_filter}")

    if intent == "greeting":
        return {"answer": "K√≠nh ch√†o Qu√Ω kh√°ch. T√¥i l√† Tr·ª£ l√Ω AI chuy√™n tr√°ch v·ªÅ VƒÉn h√≥a & Giao th√¥ng.\nT√¥i c√≥ th·ªÉ gi√∫p b·∫°n tra c·ª©u l·ªô tr√¨nh xe bu√Ωt TP.HCM ho·∫∑c th√¥ng tin du l·ªãch Vi·ªát Nam.", "sources": [], "images": []}

    # --- X·ª¨ L√ù BUS (ƒê√É FIX LOGIC TR√çCH XU·∫§T) ---
    if intent == "bus":
        start_loc = None
        end_loc = None
        separators = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "]
        # M·ªü r·ªông prefix ƒë·ªÉ b·∫Øt d√≠nh input ng∆∞·ªùi d√πng
        start_prefixes = [
            "ƒëi t·ª´", "t·ª´", "t√¨m ƒë∆∞·ªùng t·ª´", "ch·ªâ ƒë∆∞·ªùng t·ª´", "ƒë∆∞·ªùng ƒëi t·ª´", 
            "l·ªô tr√¨nh t·ª´", "xe bu√Ωt t·ª´", "b·∫Øt xe t·ª´", "gh√©", "ch·∫°y t·ª´", "h∆∞·ªõng d·∫´n b·∫Øt xe bu√Ωt t·ª´",
            "l·ªô tr√¨nh xe bu√Ωt ƒëi t·ª´", "l·ªô tr√¨nh ƒëi xe bu√Ωt t·ª´"
        ]

        found_sep = None
        for sep in separators:
            if sep in lower_q:
                found_sep = sep
                break
        
        if found_sep:
            try:
                parts = lower_q.split(found_sep, 1)
                end_loc = parts[1].strip()
                start_raw = parts[0].strip()
                for prefix in start_prefixes:
                    if start_raw.startswith(prefix):
                        start_raw = start_raw[len(prefix):].strip()
                        break 
                start_loc = start_raw
            except: pass
        
        if start_loc and end_loc:
            try:
                # [CORE FIX] G·ªçi h√†m l√†m s·∫°ch th·∫ßn th√°nh
                start_loc = clean_entity_name(start_loc)
                end_loc = clean_entity_name(end_loc)
                
                logger.info(f"BUS SEARCH: Start='{start_loc}' | End='{end_loc}'")

                bus_result = await asyncio.to_thread(bus_bot.solve_route, start_loc, end_loc)
                
                if bus_result.get("status") == "ambiguous":
                    return {
                        "answer": bus_result["message"], 
                        "options": bus_result["options"],
                        "context_type": "bus_ambiguity",
                        "original_request": {"start": start_loc, "end": end_loc, "type": bus_result["point_type"]},
                        "sources": [], "images": []
                    }

                if bus_result.get("status") == "error":
                    return {"answer": bus_result["message"], "sources": [], "images": []}
                
                raw_text = bus_result["text"]
                path_coords = bus_result.get("path_coords", [])
                
                google_link = ""
                if path_coords:
                    s = path_coords[0]
                    e = path_coords[-1]
                    google_link = f"https://www.google.com/maps/dir/?api=1&origin={s[1]},{s[0]}&destination={e[1]},{e[0]}&travelmode=transit"

                polish_prompt = f"""
                D·ªØ li·ªáu l·ªô tr√¨nh: \"\"\"{raw_text}\"\"\"
                Y√äU C·∫¶U: Vi·∫øt l·∫°i h∆∞·ªõng d·∫´n di chuy·ªÉn chuy√™n nghi·ªáp.
                1. Tr√¨nh b√†y c√°c b∆∞·ªõc r√µ r√†ng.
                2. In ƒë·∫≠m t√™n tr·∫°m, s·ªë xe.
                3. B·∫Øt bu·ªôc hi·ªÉn th·ªã B·∫£ng gi√° v√©.
                4. VƒÉn phong l·ªãch s·ª±, kh√¥ng emoji.
                """
                final_res = await asyncio.to_thread(llm_model.generate_content, polish_prompt)
                
                answer_text = final_res.text
                if google_link:
                    answer_text += f"\n\nüîó **[Xem b·∫£n ƒë·ªì l·ªô tr√¨nh tr√™n Google Maps]({google_link})**"

                return {"answer": answer_text, "sources": [], "images": []}
            except Exception as e:
                logger.error(f"BUS ERROR: {e}")
                return {"answer": "H·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi tra c·ª©u xe bu√Ωt. Vui l√≤ng th·ª≠ l·∫°i sau.", "sources": [], "images": []}
        else:
            return {"answer": "Vui l√≤ng cung c·∫•p ƒëi·ªÉm ƒëi v√† ƒëi·ªÉm ƒë·∫øn (V√≠ d·ª•: T·ª´ B·∫øn Th√†nh t·ªõi Aeon Mall) ƒë·ªÉ t√¥i t√¨m l·ªô tr√¨nh.", "sources": [], "images": []}

    # --- X·ª¨ L√ù OOD / TOURISM ---
    if intent == "ood":
        general_answer = await fallback_general_knowledge(question)
        return {"answer": general_answer, "sources": [], "images": []}

    # X·ª≠ l√Ω province filter an to√†n
    final_province = request.province if request.province else location_filter
    search_query = question
    
    if final_province:
        if isinstance(final_province, list) and len(final_province) > 0:
            search_query = final_province[0] 
        elif isinstance(final_province, str):
            search_query = final_province

    # L√†m s·∫°ch l·∫ßn cu·ªëi
    search_query = clean_entity_name(search_query)

    try:
        search_results = await hybrid_search_tourism(search_query, final_province)
    except Exception as e:
        logger.error(f"SEARCH ERROR: {e}")
        search_results = []
    
    if search_results:
        image_urls = []
        for item in search_results:
            node_data = item.get('node', {})
            url = node_data.get('image_url')
            if url and isinstance(url, str) and url.startswith("http"):
                image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2] 

        context_str = "\n".join([f"- {item['node']['name']} (T·ªânh: {item.get('province_name', 'Ch∆∞a r√µ')}): {item['node']['content']}" for item in search_results])
        
        if mode == "list":
            rag_prompt = f"""
            VAI TR√í: Tr·ª£ l√Ω du l·ªãch. NHI·ªÜM V·ª§: Li·ªát k√™.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U: Li·ªát k√™ (t·ªëi thi·ªÉu 3). Ghi r√µ T√™n v√† T·ªânh/Th√†nh. KH√îNG emoji.
            """
        else:
            rag_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a & du l·ªãch.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U: Ng·∫Øn g·ªçn. C·∫•u tr√∫c: 1. T·ªïng quan (V·ªã tr√≠ T·ªânh/Th√†nh), 2. G·∫°ch ƒë·∫ßu d√≤ng chi ti·∫øt.
            """

        res = await asyncio.to_thread(llm_model.generate_content, rag_prompt)
        return {"answer": res.text, "sources": search_results, "images": final_imgs}
    
    else:
        # Fallback cu·ªëi c√πng n·∫øu kh√¥ng t√¨m th·∫•y g√¨
        general_answer = await fallback_general_knowledge(question)
        return {"answer": general_answer, "sources": [], "images": []}

# --- 5. API X·ª¨ L√ù ·∫¢NH ---
@app.post("/chat_with_image")
async def chat_with_image_endpoint(file: UploadFile = File(...), question: str = Form(...)):
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        vision_prompt = "ƒê√¢y l√† ƒë·ªãa ƒëi·ªÉm n√†o? Ch·ªâ tr·∫£ v·ªÅ t√™n ch√≠nh x√°c. N·∫øu kh√¥ng bi·∫øt, tr·∫£ v·ªÅ 'Unknown'."
        loop = asyncio.get_running_loop()
        vision_res = await loop.run_in_executor(None, lambda: llm_model.generate_content([vision_prompt, image]))
        detected_name = vision_res.text.strip()
        
        if "Unknown" in detected_name or len(detected_name) < 2:
            return {"detected_location": None, "answer": "Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ƒë·ªãa ƒëi·ªÉm trong ·∫£nh.", "sources": [], "images": []}
             
        search_results = await hybrid_search_tourism(detected_name)
        
        image_urls = []
        if search_results:
            for item in search_results:
                url = item.get('node', {}).get('image_url')
                if url and isinstance(url, str) and url.startswith("http"): image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2]

        if search_results:
            context_str = "\n".join([f"- {item['node']['name']}: {item['node']['content']}" for item in search_results[:3]])
            final_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a.
            ƒê·ªäA ƒêI·ªÇM: {detected_name}
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: {question}
            Y√äU C·∫¶U: Tr·∫£ l·ªùi chuy√™n nghi·ªáp. KH√îNG emoji.
            """
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(final_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": search_results, "images": final_imgs}
        else:
            general_prompt = f"ƒê·ªãa ƒëi·ªÉm: '{detected_name}'. C√¢u h·ªèi: '{question}'. Tr·∫£ l·ªùi chi ti·∫øt. KH√îNG emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(general_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": [], "images": []}

    except Exception as e:
        logger.error(f"IMAGE ERROR: {e}")
        return {"answer": "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω h√¨nh ·∫£nh.", "sources": [], "images": []}