import os
import logging
import asyncio
import unicodedata
import io
import json
import time
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from neo4j import AsyncGraphDatabase
import google.generativeai as genai
from PIL import Image

from bus_core import BusBotV13

# --- 1. C·∫§U H√åNH LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger(__name__)

# --- 2. LOAD BI·∫æN M√îI TR∆Ø·ªúNG ---
load_dotenv(override=True)

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j") 
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

# --- 3. KH·ªûI T·∫†O MODEL & DB ---
if not GEMINI_API_KEY:
    logger.error("‚ùå CH∆ØA C√ì GEMINI_API_KEY TRONG FILE .ENV")

genai.configure(api_key=GEMINI_API_KEY)
llm_model = genai.GenerativeModel('gemini-2.0-flash') 

logger.info("SYSTEM: Loading Vector Model...")
model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")
logger.info("SYSTEM: Vector Model Loaded.")

tourism_driver = AsyncGraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
logger.info("SYSTEM: Initializing BusBot...")
bus_bot = BusBotV13()
logger.info("SYSTEM: BusBot Ready.")

def normalize_text(text: str) -> str:
    if not text: return ""
    return unicodedata.normalize('NFC', text).lower().strip()

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield
    await tourism_driver.close()
    bus_bot.close()

app = FastAPI(title="Professional Travel & Transport AI", lifespan=lifespan)

# Mount th∆∞ m·ª•c ·∫£nh tƒ©nh (d√π ∆∞u ti√™n d√πng link online, v·∫´n gi·ªØ c·∫•u h√¨nh n√†y ƒë·ªÉ tr√°nh l·ªói n·∫øu c√≥ request t·ªõi)
if not os.path.exists("images_items"):
    os.makedirs("images_items")
app.mount("/images_items", StaticFiles(directory="images_items"), name="images")

# --- 4. DANH S√ÅCH T·ª™ KH√ìA ---
QUESTION_MARKERS = [
    "?", "l√† g√¨", "c√°i g√¨", "vi·ªác g√¨", "th·ª© g√¨", "ƒëi·ªÅu g√¨",
    "·ªü ƒë√¢u", "ch·ªó n√†o", "n∆°i n√†o", "khu n√†o", "ƒë√¢u",
    "khi n√†o", "l√∫c n√†o", "bao gi·ªù", "h·ªìi n√†o", "ng√†y n√†o",
    "ai", "ng∆∞·ªùi n√†o", "nh√¢n v·∫≠t n√†o", "v·ªã n√†o",
    "t·∫°i sao", "v√¨ sao", "nguy√™n nh√¢n", "l√Ω do", "sao l·∫°i",
    "th·∫ø n√†o", "ra sao", "nh∆∞ n√†o", "l√†m sao", "c√°ch n√†o",
    "bao nhi√™u", "bao l√¢u", "bao xa", "m·∫•y", "s·ªë l∆∞·ª£ng",
    "c√≥...kh√¥ng", "ƒë∆∞·ª£c kh√¥ng", "c√≥ ph·∫£i", "kh√¥ng ·∫°", "ch∆∞a", "h·∫£", "h·ª≠",
    "cho h·ªèi", "mu·ªën h·ªèi", "t√¨m hi·ªÉu", "ch·ªâ gi√∫p", "h∆∞·ªõng d·∫´n", "t∆∞ v·∫•n",
    "th√¥ng tin", "chi ti·∫øt", "gi·ªõi thi·ªáu", "k·ªÉ v·ªÅ", "n√≥i v·ªÅ", "li·ªát k√™", "danh s√°ch"
]

# --- 5. LOGIC T√åM KI·∫æM TOURISM (L·∫•y image_url) ---
async def hybrid_search_tourism(text: str, province_filter: str = None):
    search_text_norm = normalize_text(text)
    records = []
    
    async with tourism_driver.session() as session:
        # TH1: C√≥ l·ªçc theo t·ªânh -> T√¨m ki·∫øm di·ªán r·ªông (List)
        if province_filter and len(province_filter) > 2:
            province_norm = normalize_text(province_filter)
            # TƒÉng LIMIT ƒë·ªÉ l·∫•y nhi·ªÅu ƒë·ªãa ƒëi·ªÉm cho vi·ªác li·ªát k√™
            cypher_loc = """
            MATCH (node:Searchable)-[:LOCATED_IN]->(p:Province)
            WHERE toLower(p.name) CONTAINS $province_norm
            AND (toLower(node.name) CONTAINS $text_norm OR toLower(node.content) CONTAINS $text_norm)
            RETURN elementId(node) as id, node, 1.5 as score, p.name as province_name, 'location_filter' as source_type
            LIMIT 15
            """
            try:
                r_loc = await session.run(cypher_loc, province_norm=province_norm, text_norm=search_text_norm)
                records.extend([record.data() async for record in r_loc])
            except Exception as e:
                logger.error(f"Error Loc Search: {e}")

        # TH2: Vector Search & Keyword Search (B·ªï tr·ª£ n·∫øu √≠t k·∫øt qu·∫£)
        if len(records) < 5: 
            loop = asyncio.get_running_loop()
            vector = await loop.run_in_executor(None, lambda: model.encode(text).tolist())
            
            cypher_vector = "CALL db.index.vector.queryNodes('searchable_index', 50, $vector) YIELD node, score OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, score, p.name as province_name, 'vector' as source_type"
            cypher_keyword = "MATCH (node:Searchable) WHERE toLower(node.name) CONTAINS $text_norm OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, 1.0 as score, p.name as province_name, 'keyword' as source_type LIMIT 20"
            
            try:
                r1 = await session.run(cypher_vector, vector=vector)
                records.extend([record.data() async for record in r1])
            except: pass
            try:
                r2 = await session.run(cypher_keyword, text_norm=search_text_norm)
                records.extend([record.data() async for record in r2])
            except: pass

    # L·ªçc tr√πng v√† ch·∫•m ƒëi·ªÉm l·∫°i
    unique_results = {}
    for r in records:
        uid = r['id']
        # Gi·∫£m ƒëi·ªÉm n·∫øu sai t·ªânh (Strict filtering logic)
        if province_filter and r.get('province_name'):
            if normalize_text(province_filter) not in normalize_text(r['province_name']):
                r['score'] = r['score'] * 0.1

        # Ng∆∞·ª°ng vector (ƒë·ªÉ lo·∫°i b·ªè k·∫øt qu·∫£ r√°c)
        if r['source_type'] == 'vector' and r['score'] < 0.65: continue
        
        if uid not in unique_results:
            unique_results[uid] = r
            if r['source_type'] == 'location_filter':
                unique_results[uid]['score'] = 10.0
            else:
                unique_results[uid]['score'] = 10.0 if r['source_type'] == 'keyword' else r['score']
    
    sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
    return sorted_results[:10] # L·∫•y t·ªëi ƒëa 10 k·∫øt qu·∫£

# --- 6. FALLBACK LOGIC ---
async def fallback_general_knowledge(question: str):
    system_prompt = f"""
    VAI TR√í: Chuy√™n gia t∆∞ v·∫•n du l·ªãch v√† vƒÉn h√≥a Vi·ªát Nam.
    C√ÇU H·ªéI: "{question}"
    Y√äU C·∫¶U:
    1. Tr·∫£ l·ªùi ch√≠nh x√°c, kh√°ch quan, ng√¥n ng·ªØ trang tr·ªçng (Professional Tone).
    2. TUY·ªÜT ƒê·ªêI KH√îNG s·ª≠ d·ª•ng Emoji.
    3. Tr√¨nh b√†y vƒÉn b·∫£n r√µ r√†ng b·∫±ng Markdown.
    4. T·∫≠p trung v√†o th√¥ng tin th·ª±c t·∫ø.
    """
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: llm_model.generate_content(system_prompt))
    return response.text

class ChatRequest(BaseModel):
    question: str
    province: Optional[str] = None

# ==========================================
#               MAIN CHAT API
# ==========================================
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()
    question = request.question.strip()
    logger.info(f"REQ: {question}")
    
    # --- 1. ROUTER TH√îNG MINH (Intent + Location + Mode) ---
    router_prompt = f"""
    Ph√¢n t√≠ch c√¢u h·ªèi: "{question}".
    Nhi·ªám v·ª•:
    1. Intent: "greeting" | "bus" | "tourism".
    2. Location: Tr√≠ch xu·∫•t t√™n T·ªânh/Th√†nh ph·ªë/Qu·∫≠n Huy·ªán (n·∫øu c√≥).
    3. Mode: 
       - "list": N·∫øu h·ªèi danh s√°ch, li·ªát k√™, s·ªë l∆∞·ª£ng (VD: "C√≥ nh·ªØng ch√πa n√†o", "C√°c ƒë·ªãa ƒëi·ªÉm ƒë·∫πp", "Li·ªát k√™...").
       - "detail": N·∫øu h·ªèi chi ti·∫øt v·ªÅ m·ªôt ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ (VD: "Gi·ªõi thi·ªáu ch√πa S√πng Nghi√™m", "Thuy·∫øt minh v·ªÅ...").
    
    JSON Output: {{ "intent": "...", "location": "...", "mode": "..." }}
    """
    
    intent = "tourism"
    start_loc = None
    end_loc = None
    location_filter = None
    mode = "detail"

    try:
        res = await asyncio.to_thread(llm_model.generate_content, router_prompt)
        clean = res.text.strip().replace("```json", "").replace("```", "")
        parsed = json.loads(clean)
        intent = parsed.get("intent", "tourism")
        location_filter = parsed.get("location")
        mode = parsed.get("mode", "detail")
    except: pass

    # --- 2. LOGIC ƒêI·ªÄU H∆Ø·ªöNG TH·ª¶ C√îNG (QUAN TR·ªåNG: ƒê∆ØA L√äN TR∆Ø·ªöC H·∫æT) ---
    lower_q = question.lower()
    
    # [FIX] Ki·ªÉm tra Intent BUS ƒë·ªôc l·∫≠p (kh√¥ng ph·ª• thu·ªôc v√†o c√¢u h·ªèi nghi v·∫•n)
    if "ƒë·∫øn" in lower_q and ("t·ª´" in lower_q or "ƒëi" in lower_q or "t√¨m ƒë∆∞·ªùng" in lower_q or "ch·ªâ ƒë∆∞·ªùng" in lower_q):
        intent = "bus"
    
    # Ki·ªÉm tra Intent GREETING ho·∫∑c √©p v·ªÅ TOURISM n·∫øu c√≥ t·ª´ ƒë·ªÉ h·ªèi
    has_question_word = any(marker in lower_q for marker in QUESTION_MARKERS)
    
    if intent != "bus": # Ch·ªâ check ti·∫øp n·∫øu ch∆∞a ph·∫£i l√† bus
        if has_question_word:
            if intent == "greeting": intent = "tourism" # √âp v·ªÅ tourism n·∫øu AI nh·∫≠n nh·∫ßm greeting
        else:
            greeting_words = ["xin ch√†o", "hello", "hi bot", "ch√†o b·∫°n", "alo", "hi there"]
            if any(w == lower_q or lower_q.startswith(w) for w in greeting_words) and len(lower_q) < 20:
                intent = "greeting"

    if location_filter and mode == "detail":
        if any(w in lower_q for w in ["n√†o", "g√¨", "nh·ªØng", "c√°c", "ƒë√¢u"]):
            mode = "list"

    logger.info(f"üîç INTENT: {intent} | LOC: {location_filter} | MODE: {mode}")

    if intent == "greeting":
        greeting_msg = (
            "K√≠nh ch√†o Qu√Ω kh√°ch. T√¥i l√† Tr·ª£ l√Ω AI chuy√™n tr√°ch v·ªÅ VƒÉn h√≥a, Du l·ªãch v√† Giao th√¥ng c√¥ng c·ªông.\n\n"
            "T√¥i c√≥ th·ªÉ h·ªó tr·ª£ Qu√Ω kh√°ch:\n"
            "- Tra c·ª©u l·ªô tr√¨nh xe bu√Ωt t·ªëi ∆∞u.\n"
            "- Cung c·∫•p th√¥ng tin chuy√™n s√¢u v·ªÅ di t√≠ch, danh lam th·∫Øng c·∫£nh Vi·ªát Nam.\n\n"
            "Qu√Ω kh√°ch c·∫ßn t√¨m hi·ªÉu th√¥ng tin g√¨ h√¥m nay?"
        )
        return {"answer": greeting_msg, "sources": [], "images": []}

    # --- X·ª¨ L√ù BUS (C·∫¨P NH·∫¨T LOGIC BUTTON & PROMPT) ---
    if intent == "bus":
        # Parse ƒëi·ªÉm ƒëi/ƒë·∫øn th·ªß c√¥ng n·∫øu AI ch∆∞a b·∫Øt ƒë∆∞·ª£c
        if not start_loc or not end_loc:
            if "ƒë·∫øn" in lower_q:
                try:
                    parts = lower_q.split("ƒë·∫øn")
                    end_loc = parts[1].strip()
                    start_raw = parts[0]
                    for w in ["ƒëi t·ª´", "t√¨m ƒë∆∞·ªùng t·ª´", "ch·ªâ ƒë∆∞·ªùng t·ª´", "t·ª´", "ƒë∆∞·ªùng ƒëi"]:
                        start_raw = start_raw.replace(w, "")
                    start_loc = start_raw.strip()
                except: pass
        
        if start_loc and end_loc:
            try:
                # G·ªçi BusBot
                bus_result = await asyncio.to_thread(bus_bot.solve_route, start_loc, end_loc)
                
                # TR∆Ø·ªúNG H·ª¢P 1: C√ì NHI·ªÄU L·ª∞A CH·ªåN (AMBIGUOUS) -> TR·∫¢ V·ªÄ OPTIONS CHO CLIENT
                if bus_result.get("status") == "ambiguous":
                    return {
                        "answer": bus_result["message"], 
                        "options": bus_result["options"], # List c√°c n√∫t b·∫•m
                        "context_type": "bus_ambiguity", # ƒê√°nh d·∫•u ƒë·ªÉ client bi·∫øt
                        "original_request": {"start": start_loc, "end": end_loc, "type": bus_result["point_type"]},
                        "sources": [], 
                        "images": []
                    }

                # TR∆Ø·ªúNG H·ª¢P 2: L·ªñI
                if bus_result.get("status") == "error":
                    return {"answer": bus_result["message"], "sources": [], "images": []}
                
                # TR∆Ø·ªúNG H·ª¢P 3: TH√ÄNH C√îNG (C√ì L·ªò TR√åNH)
                raw_text = bus_result["text"]
                path_coords = bus_result.get("path_coords", [])
                
                google_link = ""
                if path_coords:
                    s = path_coords[0]
                    e = path_coords[-1]
                    google_link = f"https://www.google.com/maps/dir/?api=1&origin={s[1]},{s[0]}&destination={e[1]},{e[0]}&travelmode=transit"

                # Prompt n√†y √©p AI ph·∫£i hi·ªÉn th·ªã ƒë√∫ng b·∫£ng gi√° v√© 3 lo·∫°i
                polish_prompt = f"""
                D·ªØ li·ªáu l·ªô tr√¨nh: \"\"\"{raw_text}\"\"\"
                Y√äU C·∫¶U: Vi·∫øt l·∫°i h∆∞·ªõng d·∫´n di chuy·ªÉn chuy√™n nghi·ªáp.
                1. Tr√¨nh b√†y c√°c b∆∞·ªõc r√µ r√†ng.
                2. In ƒë·∫≠m t√™n tr·∫°m, s·ªë xe.
                3. B·∫Øt bu·ªôc hi·ªÉn th·ªã B·∫£ng gi√° v√© (G·ªìm: V√© th∆∞·ªùng, HSSV, Ng∆∞·ªùi cao tu·ªïi) d·ª±a tr√™n d·ªØ li·ªáu.
                4. VƒÉn phong l·ªãch s·ª±, kh√¥ng emoji.
                """
                final_res = await asyncio.to_thread(llm_model.generate_content, polish_prompt)
                
                answer_text = final_res.text
                if google_link:
                    answer_text += f"\n\nüîó **[Xem b·∫£n ƒë·ªì l·ªô tr√¨nh tr√™n Google Maps]({google_link})**"

                logger.info(f"DONE [BUS]: {time.time()-start_time:.2f}s")
                return {"answer": answer_text, "sources": [], "images": []}
            except Exception as e:
                return {"answer": f"L·ªói h·ªá th·ªëng: {str(e)}", "sources": [], "images": []}
        else:
            return {"answer": "Vui l√≤ng cung c·∫•p ƒëi·ªÉm ƒëi v√† ƒëi·ªÉm ƒë·∫øn (V√≠ d·ª•: T·ª´ B·∫øn Th√†nh ƒë·∫øn ƒê·∫ßm Sen) ƒë·ªÉ t√¥i t√¨m l·ªô tr√¨nh.", "sources": [], "images": []}

    # --- X·ª¨ L√ù TOURISM (FULL LOGIC) ---
    final_province = request.province if request.province else location_filter
    search_results = await hybrid_search_tourism(question, final_province)
    
    if search_results:
        # 1. X·ª≠ l√Ω ·∫£nh: CH·ªà L·∫§Y URL ONLINE (B·ªè qua local path theo y√™u c·∫ßu)
        image_urls = []
        for item in search_results:
            node_data = item.get('node', {})
            
            # Ch·ªâ l·∫•y tr∆∞·ªùng image_url
            url = node_data.get('image_url')
            
            # Ki·ªÉm tra h·ª£p l·ªá (ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng http)
            if url and isinstance(url, str) and url.startswith("http"):
                image_urls.append(url)
        
        # L·ªçc tr√πng v√† l·∫•y t·ªëi ƒëa 2 ·∫£nh (THEO Y√äU C·∫¶U M·ªöI)
        final_imgs = list(dict.fromkeys(image_urls))[:2] 

        # 2. T·∫°o Context cho LLM
        context_str = "\n".join([f"- {item['node']['name']}: {item['node']['content']}" for item in search_results])
        
        # 3. Ch·ªçn Prompt theo Mode (List vs Detail)
        if mode == "list":
            rag_prompt = f"""
            VAI TR√í: H∆∞·ªõng d·∫´n vi√™n du l·ªãch chuy√™n nghi·ªáp.
            NHI·ªÜM V·ª§: Li·ªát k√™ danh s√°ch c√°c ƒë·ªãa ƒëi·ªÉm.
            D·ªÆ LI·ªÜU CUNG C·∫§P: {context_str}
            C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: "{question}"
            
            Y√äU C·∫¶U TR·∫¢ L·ªúI:
            1. M·ªü ƒë·∫ßu: "T·∫°i {location_filter if location_filter else 'khu v·ª±c n√†y'}, c√≥ c√°c ƒë·ªãa ƒëi·ªÉm n·ªïi ti·∫øng sau:"
            2. Li·ªát k√™ danh s√°ch (t·ªëi thi·ªÉu 3 ƒëi·ªÉm n·∫øu c√≥ trong d·ªØ li·ªáu).
            3. M·ªói ƒëi·ªÉm m√¥ t·∫£ ng·∫Øn g·ªçn 2-3 c√¢u v·ªÅ ƒëi·ªÉm ƒë·∫∑c s·∫Øc nh·∫•t.
            4. VƒÉn phong trang tr·ªçng, KH√îNG s·ª≠ d·ª•ng emoji.
            """
        else:
            rag_prompt = f"""
            VAI TR√í: Nh√† nghi√™n c·ª©u vƒÉn h√≥a v√† H∆∞·ªõng d·∫´n vi√™n cao c·∫•p.
            D·ªÆ LI·ªÜU CUNG C·∫§P: {context_str}
            C√ÇU H·ªéI NG∆Ø·ªúI D√ôNG: "{question}"
            
            Y√äU C·∫¶U TR·∫¢ L·ªúI:
            1. Phong c√°ch: Trang tr·ªçng, uy√™n b√°c, gi√†u c·∫£m x√∫c. TUY·ªÜT ƒê·ªêI KH√îNG d√πng emoji.
            2. C·∫•u tr√∫c b√†i thuy·∫øt minh:
               - M·ªü ƒë·∫ßu: Gi·ªõi thi·ªáu ·∫•n t∆∞·ª£ng.
               - Th√¢n b√†i: Chi ti·∫øt l·ªãch s·ª≠, ki·∫øn tr√∫c, gi√° tr·ªã vƒÉn h√≥a (S·ª≠ d·ª•ng g·∫°ch ƒë·∫ßu d√≤ng ƒë·ªÉ tr√¨nh b√†y).
               - K·∫øt lu·∫≠n: √ù nghƒ©a c·ªßa di t√≠ch.
            3. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ d·ªØ li·ªáu cung c·∫•p, kh√¥ng b·ªãa ƒë·∫∑t.
            """

        res = await asyncio.to_thread(llm_model.generate_content, rag_prompt)
        logger.info(f"DONE [RAG]: {time.time()-start_time:.2f}s")
        return {"answer": res.text, "sources": search_results, "images": final_imgs}
    
    else:
        general_answer = await fallback_general_knowledge(question)
        logger.info(f"DONE [FALLBACK]: {time.time()-start_time:.2f}s")
        return {"answer": general_answer, "sources": [], "images": []}

# --- API X·ª¨ L√ù ·∫¢NH ƒê·∫¶U V√ÄO ---
@app.post("/chat_with_image")
async def chat_with_image_endpoint(file: UploadFile = File(...), question: str = Form(...)):
    start_time = time.time()
    logger.info(f"REQ [IMG]: {question}")
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # 1. Nh·∫≠n di·ªán ƒë·ªãa ƒëi·ªÉm
        vision_prompt = "ƒê√¢y l√† ƒë·ªãa ƒëi·ªÉm n√†o? Ch·ªâ tr·∫£ v·ªÅ t√™n ch√≠nh x√°c. N·∫øu kh√¥ng bi·∫øt, tr·∫£ v·ªÅ 'Unknown'."
        loop = asyncio.get_running_loop()
        vision_res = await loop.run_in_executor(None, lambda: llm_model.generate_content([vision_prompt, image]))
        detected_name = vision_res.text.strip()
        
        if "Unknown" in detected_name or len(detected_name) < 2:
            return {"detected_location": None, "answer": "H·ªá th·ªëng ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ƒë·ªãa ƒëi·ªÉm trong ·∫£nh. Vui l√≤ng cung c·∫•p ·∫£nh r√µ h∆°n.", "sources": [], "images": []}
             
        # 2. T√¨m ki·∫øm th√¥ng tin trong Neo4j
        search_results = await hybrid_search_tourism(detected_name)
        
        # 3. L·∫•y ·∫£nh minh h·ªça (Ch·ªâ l·∫•y URL Online)
        image_urls = []
        if search_results:
            for item in search_results:
                node_data = item.get('node', {})
                url = node_data.get('image_url')
                if url and isinstance(url, str) and url.startswith("http"): 
                    image_urls.append(url)
        
        # L·∫•y t·ªëi ƒëa 2 ·∫£nh
        final_imgs = list(dict.fromkeys(image_urls))[:2]

        # 4. Tr·∫£ l·ªùi c√¢u h·ªèi
        if search_results:
            context_str = "\n".join([f"- {item['node']['name']}: {item['node']['content']}" for item in search_results[:3]])
            final_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a.
            ƒê·ªäA ƒêI·ªÇM NH·∫¨N DI·ªÜN T·ª™ ·∫¢NH: {detected_name}
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: {question}
            Y√äU C·∫¶U: Tr·∫£ l·ªùi chuy√™n nghi·ªáp, c·∫•u tr√∫c r√µ r√†ng, KH√îNG emoji.
            """
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(final_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": search_results, "images": final_imgs}
        else:
            general_prompt = f"ƒê·ªãa ƒëi·ªÉm trong ·∫£nh l√† '{detected_name}'. C√¢u h·ªèi: '{question}'. H√£y tr·∫£ l·ªùi chi ti·∫øt v·ªõi vƒÉn phong chuy√™n gia, kh√¥ng d√πng emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(general_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": [], "images": []}

    except Exception as e:
        logger.error(f"ERROR: {e}")
        return {"answer": "ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω ·∫£nh.", "sources": [], "images": []}