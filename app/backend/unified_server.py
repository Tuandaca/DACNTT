import os
import logging
import asyncio
import unicodedata
import io
import json
import time
import re
from typing import Optional, Union, List
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from neo4j import AsyncGraphDatabase
import google.generativeai as genai
from PIL import Image

from bus_core import BusBotV13

# --- 1. C·∫§U H√åNH LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger(__name__)

# --- 2. LOAD BI·∫æN M√îI TR∆Ø·ªúNG ---
load_dotenv(override=True)

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j") 
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

# --- 3. KH·ªûI T·∫†O MODEL & DB ---
if not GEMINI_API_KEY:
    logger.error("‚ùå CH∆ØA C√ì GEMINI_API_KEY TRONG FILE .ENV")

genai.configure(api_key=GEMINI_API_KEY)
llm_model = genai.GenerativeModel('gemini-1.5-flash') 

logger.info("SYSTEM: Loading Vector Model...")
model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")
logger.info("SYSTEM: Vector Model Loaded.")

tourism_driver = AsyncGraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
logger.info("SYSTEM: Initializing BusBot...")
bus_bot = BusBotV13()
logger.info("SYSTEM: BusBot Ready.")

def normalize_text(text: str) -> str:
    if not text: return ""
    return unicodedata.normalize('NFC', text).lower().strip()

# --- H√ÄM L√ÄM S·∫†CH T√äN ƒê·ªäA ƒêI·ªÇM (FIX L·ªñI TR√çCH XU·∫§T TH·ª™A T·ª™ KH√ìA) ---
def clean_entity_name(raw_text: str) -> str:
    if not raw_text: return ""
    # Danh s√°ch t·ª´ th·ª´a th∆∞·ªùng g·∫∑p do LLM tr√≠ch xu·∫•t d∆∞
    stopwords = [
        "l·ªô tr√¨nh xe bu√Ωt ƒëi t·ª´", "l·ªô tr√¨nh ƒëi t·ª´", "h∆∞·ªõng d·∫´n b·∫Øt xe bu√Ωt t·ª´", 
        "h∆∞·ªõng d·∫´n ƒëi t·ª´", "c√°ch ƒëi t·ª´", "ƒë∆∞·ªùng ƒëi t·ª´", "xe bu√Ωt t·ª´", "b·∫Øt xe t·ª´",
        "ƒëi t·ª´", "ƒë·∫øn", "t·ªõi", "v·ªÅ", "sang", "qua", "t·∫°i", "·ªü", "khu v·ª±c",
        "t√¨m ƒë∆∞·ªùng", "ch·ªâ ƒë∆∞·ªùng", "cho t√¥i h·ªèi v·ªÅ", "th√¥ng tin v·ªÅ"
    ]
    cleaned = raw_text.lower()
    for word in stopwords:
        if cleaned.startswith(word):
            cleaned = cleaned.replace(word, "", 1).strip()
    
    return cleaned

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield
    await tourism_driver.close()
    bus_bot.close()

app = FastAPI(title="Professional Travel & Transport AI", lifespan=lifespan)

if not os.path.exists("images_items"):
    os.makedirs("images_items")
app.mount("/images_items", StaticFiles(directory="images_items"), name="images")

# --- 4. DANH S√ÅCH T·ª™ KH√ìA ---
QUESTION_MARKERS = [
    "?", "l√† g√¨", "c√°i g√¨", "vi·ªác g√¨", "th·ª© g√¨", "ƒëi·ªÅu g√¨",
    "·ªü ƒë√¢u", "ch·ªó n√†o", "n∆°i n√†o", "khu n√†o", "ƒë√¢u",
    "khi n√†o", "l√∫c n√†o", "bao gi·ªù", "h·ªìi n√†o", "ng√†y n√†o",
    "ai", "ng∆∞·ªùi n√†o", "nh√¢n v·∫≠t n√†o", "v·ªã n√†o",
    "t·∫°i sao", "v√¨ sao", "nguy√™n nh√¢n", "l√Ω do", "sao l·∫°i",
    "th·∫ø n√†o", "ra sao", "nh∆∞ n√†o", "l√†m sao", "c√°ch n√†o",
    "bao nhi√™u", "bao l√¢u", "bao xa", "m·∫•y", "s·ªë l∆∞·ª£ng",
    "c√≥...kh√¥ng", "ƒë∆∞·ª£c kh√¥ng", "c√≥ ph·∫£i", "kh√¥ng ·∫°", "ch∆∞a", "h·∫£", "h·ª≠",
    "cho h·ªèi", "mu·ªën h·ªèi", "t√¨m hi·ªÉu", "ch·ªâ gi√∫p", "h∆∞·ªõng d·∫´n", "t∆∞ v·∫•n",
    "th√¥ng tin", "chi ti·∫øt", "gi·ªõi thi·ªáu", "k·ªÉ v·ªÅ", "n√≥i v·ªÅ", "li·ªát k√™", "danh s√°ch"
]

# --- 5. LOGIC T√åM KI·∫æM TOURISM (ƒê√É FIX L·ªñI 500 V·ªöI LIST PROVINCE) ---
async def hybrid_search_tourism(text: str, province_filter: Union[str, List[str]] = None):
    # L√†m s·∫°ch text t√¨m ki·∫øm tr∆∞·ªõc
    text = clean_entity_name(text)
    search_text_norm = normalize_text(text)
    records = []
    
    async with tourism_driver.session() as session:
        # X·ª≠ l√Ω province_filter cho Cypher (ch·ªâ l·∫•y c√°i ƒë·∫ßu ti√™n n·∫øu l√† list ƒë·ªÉ query nhanh)
        p_filter_cypher = ""
        if province_filter:
            if isinstance(province_filter, list) and len(province_filter) > 0:
                p_filter_cypher = normalize_text(province_filter[0])
            elif isinstance(province_filter, str):
                p_filter_cypher = normalize_text(province_filter)

        if len(p_filter_cypher) > 2:
            cypher_loc = """
            MATCH (node:Searchable)-[:LOCATED_IN]->(p:Province)
            WHERE toLower(p.name) CONTAINS $province_norm
            AND (toLower(node.name) CONTAINS $text_norm OR toLower(node.content) CONTAINS $text_norm)
            RETURN elementId(node) as id, node, 1.5 as score, p.name as province_name, 'location_filter' as source_type
            LIMIT 15
            """
            try:
                r_loc = await session.run(cypher_loc, province_norm=p_filter_cypher, text_norm=search_text_norm)
                records.extend([record.data() async for record in r_loc])
            except Exception as e:
                logger.error(f"Error Loc Search: {e}")

        if len(records) < 5: 
            loop = asyncio.get_running_loop()
            vector = await loop.run_in_executor(None, lambda: model.encode(text).tolist())
            
            cypher_vector = "CALL db.index.vector.queryNodes('searchable_index', 50, $vector) YIELD node, score OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, score, p.name as province_name, 'vector' as source_type"
            cypher_keyword = "MATCH (node:Searchable) WHERE toLower(node.name) CONTAINS $text_norm OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, 1.0 as score, p.name as province_name, 'keyword' as source_type LIMIT 20"
            
            try:
                r1 = await session.run(cypher_vector, vector=vector)
                records.extend([record.data() async for record in r1])
            except: pass
            try:
                r2 = await session.run(cypher_keyword, text_norm=search_text_norm)
                records.extend([record.data() async for record in r2])
            except: pass

    unique_results = {}
    for r in records:
        uid = r['id']
        
        # --- FIX BUG START: X·ª≠ l√Ω logic l·ªçc t·ªânh th√†nh an to√†n h∆°n ---
        if province_filter and r.get('province_name'):
            r_province_norm = normalize_text(r['province_name'])
            is_match = False
            
            if isinstance(province_filter, list):
                # N·∫øu filter l√† list, ch·ªâ c·∫ßn kh·ªõp 1 trong c√°c t·ªânh
                for p in province_filter:
                    if normalize_text(p) in r_province_norm:
                        is_match = True
                        break
            else:
                # N·∫øu filter l√† string
                if normalize_text(province_filter) in r_province_norm:
                    is_match = True
            
            if not is_match:
                r['score'] = r['score'] * 0.1 # Gi·∫£m ƒëi·ªÉm n·∫øu kh√¥ng ƒë√∫ng t·ªânh
        # --- FIX BUG END ---

        if r['source_type'] == 'vector' and r['score'] < 0.65: continue
        
        if uid not in unique_results:
            unique_results[uid] = r
            if r['source_type'] == 'location_filter':
                unique_results[uid]['score'] = 10.0
            else:
                unique_results[uid]['score'] = 10.0 if r['source_type'] == 'keyword' else r['score']
    
    sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
    return sorted_results[:10]

# --- 6. FALLBACK LOGIC ---
async def fallback_general_knowledge(question: str):
    system_prompt = f"""
    VAI TR√í: Chuy√™n gia t∆∞ v·∫•n du l·ªãch v√† vƒÉn h√≥a Vi·ªát Nam.
    C√ÇU H·ªéI: "{question}"
    Y√äU C·∫¶U: 
    - N·∫øu c√¢u h·ªèi v·ªÅ Y t·∫ø, T√†i ch√≠nh, Ph√°p lu·∫≠t, IT (Coding/Bug): H√£y t·ª´ ch·ªëi l·ªãch s·ª± v√† khuy√™n ng∆∞·ªùi d√πng t√¨m chuy√™n gia ƒë√∫ng lƒ©nh v·ª±c.
    - N·∫øu c√¢u h·ªèi v·ªÅ VƒÉn h√≥a/Du l·ªãch: Tr·∫£ l·ªùi ch√≠nh x√°c, kh√°ch quan.
    - KH√îNG d√πng Emoji.
    """
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: llm_model.generate_content(system_prompt))
    return response.text

class ChatRequest(BaseModel):
    question: str
    province: Optional[str] = None

# ==========================================
#               MAIN CHAT API
# ==========================================
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()
    raw_question = request.question.strip()
    question = re.sub(r'[\\/*.,?]+$', '', raw_question).strip()
    
    logger.info(f"REQ: {question}")
    lower_q = question.lower()
    
    # --- 2. NH·∫¨N DI·ªÜN INTENT TH√îNG MINH (ƒê√É C·∫¨P NH·∫¨T) ---
    is_bus_intent = False
    
    # 2.1. Blacklist t·ª´ kh√≥a Du l·ªãch/K·∫ø ho·∫°ch (∆Øu ti√™n cao h∆°n Bus)
    tourism_keywords = [
        "l·∫≠p k·∫ø ho·∫°ch", "k·∫ø ho·∫°ch", "l·ªãch tr√¨nh", "ƒëi ch∆°i", "du l·ªãch", "tham quan", 
        "tour", "m√°y bay", "kh√°ch s·∫°n", "nh√† h√†ng", "ƒÉn g√¨", "ch∆°i g√¨", 
        "t√†u h·ªèa", "t√†u cao t·ªëc", "xe kh√°ch", "limousine", # Ph∆∞∆°ng ti·ªán ngo·∫°i t·ªânh
        "h√† n·ªôi", "ƒë√† n·∫µng", "hu·∫ø", "ƒë√† l·∫°t", "ph√∫ qu·ªëc", "nha trang", "c√¥n ƒë·∫£o" # ƒê·ªãa danh ngo·∫°i t·ªânh
    ]
    
    is_tourism_override = any(k in lower_q for k in tourism_keywords)

    if not is_tourism_override:
        # 2.2. Ch·ªâ check Bus n·∫øu KH√îNG ph·∫£i l√† c√¢u h·ªèi du l·ªãch/ngo·∫°i t·ªânh
        dest_markers = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "] 
        strong_bus_words = ["xe bus", "xe bu√Ωt", "bu√Ωt", "tuy·∫øn xe", "tr·∫°m xe", "s·ªë m·∫•y", "metro", "t√†u ƒëi·ªán"]
        
        # Check 1: C√≥ t·ª´ kh√≥a m·∫°nh v·ªÅ Bus
        if any(w in lower_q for w in strong_bus_words):
            is_bus_intent = True
        # Check 2: C·∫•u tr√∫c t√¨m ƒë∆∞·ªùng n·ªôi th√†nh
        elif any(m.strip() in lower_q for m in dest_markers) and \
             any(w in lower_q for w in ["t·ª´", "ƒëi", "ƒë∆∞·ªùng", "c√°ch", "l·ªô tr√¨nh", "ch·ªâ ƒë∆∞·ªùng"]):
            is_bus_intent = True

    # Prompt Router ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ tr√°nh nh·∫ßm l·∫´n intent OOD
    router_prompt = f"""
    Ph√¢n t√≠ch c√¢u h·ªèi: "{question}".
    Nhi·ªám v·ª•:
    1. Intent: "greeting" | "bus" | "tourism" | "ood" (out-of-domain: y t·∫ø, it, t√†i ch√≠nh, l·ªùi khuy√™n ƒë·ªùi s·ªëng).
    2. Location: Tr√≠ch xu·∫•t t√™n ƒë·ªãa danh/ƒë·ªãa ƒëi·ªÉm (N·∫æU C√ì). 
       *L∆ØU √ù: Ch·ªâ l·∫•y T√äN RI√äNG, b·ªè c√°c t·ª´ nh∆∞ "l·ªô tr√¨nh", "xe bu√Ωt", "ƒëi t·ª´", "ƒë·∫øn".*
    3. Mode: "list" | "detail".
    JSON Output: {{ "intent": "...", "location": "...", "mode": "..." }}
    """
    
    intent = "bus" if is_bus_intent else "tourism"
    location_filter = None
    mode = "detail"

    try:
        # G·ªçi Router AI n·∫øu kh√¥ng ch·∫Øc ch·∫Øn
        if not is_bus_intent: 
            res = await asyncio.to_thread(llm_model.generate_content, router_prompt)
            clean = res.text.strip().replace("```json", "").replace("```", "")
            parsed = json.loads(clean)
            intent = parsed.get("intent", "tourism")
            location_filter = parsed.get("location")
            mode = parsed.get("mode", "detail")
    except: pass

    # Double check: N·∫øu AI b·∫£o l√† bus nh∆∞ng c√≥ t·ª´ kh√≥a tourism -> √âp v·ªÅ tourism
    if intent == "bus" and is_tourism_override:
        intent = "tourism"
    
    # X·ª≠ l√Ω Greeting
    has_question_word = any(marker in lower_q for marker in QUESTION_MARKERS)
    if intent != "bus":
        if has_question_word and intent == "greeting":
            intent = "tourism" # C√≥ t·ª´ ƒë·ªÉ h·ªèi th√¨ kh·∫£ nƒÉng cao kh√¥ng ph·∫£i ch√†o h·ªèi x√£ giao
        elif not has_question_word:
            greeting_words = ["xin ch√†o", "hello", "hi bot", "ch√†o b·∫°n", "alo"]
            if any(w == lower_q or lower_q.startswith(w) for w in greeting_words) and len(lower_q) < 20:
                intent = "greeting"

    if location_filter:
        # √Åp d·ª•ng h√†m l√†m s·∫°ch m·ªôt l·∫ßn n·ªØa cho ch·∫Øc ch·∫Øn
        location_filter = clean_entity_name(str(location_filter))

    logger.info(f"üîç INTENT: {intent} | LOC: {location_filter} | MODE: {mode}")

    if intent == "greeting":
        return {"answer": "K√≠nh ch√†o Qu√Ω kh√°ch. T√¥i l√† Tr·ª£ l√Ω AI chuy√™n tr√°ch v·ªÅ VƒÉn h√≥a & Giao th√¥ng.\nT√¥i c√≥ th·ªÉ gi√∫p b·∫°n tra c·ª©u l·ªô tr√¨nh xe bu√Ωt TP.HCM ho·∫∑c th√¥ng tin du l·ªãch Vi·ªát Nam.", "sources": [], "images": []}

    # --- 3. X·ª¨ L√ù BUS ---
    if intent == "bus":
        start_loc = None
        end_loc = None
        separators = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "]
        start_prefixes = [
            "ƒëi t·ª´", "t·ª´", "t√¨m ƒë∆∞·ªùng t·ª´", "ch·ªâ ƒë∆∞·ªùng t·ª´", "ƒë∆∞·ªùng ƒëi t·ª´", 
            "l·ªô tr√¨nh t·ª´", "xe bu√Ωt t·ª´", "b·∫Øt xe t·ª´", "gh√©", "ch·∫°y t·ª´", "h∆∞·ªõng d·∫´n b·∫Øt xe bu√Ωt t·ª´"
        ]

        found_sep = None
        for sep in separators:
            if sep in lower_q:
                found_sep = sep
                break
        
        if found_sep:
            try:
                parts = lower_q.split(found_sep, 1)
                end_loc = parts[1].strip()
                start_raw = parts[0].strip()
                for prefix in start_prefixes:
                    if start_raw.startswith(prefix):
                        start_raw = start_raw[len(prefix):].strip()
                        break 
                start_loc = start_raw
            except: pass
        
        if start_loc and end_loc:
            try:
                # L√†m s·∫°ch ƒë·ªãa ƒëi·ªÉm tr∆∞·ªõc khi t√¨m ƒë∆∞·ªùng
                start_loc = clean_entity_name(start_loc)
                end_loc = clean_entity_name(end_loc)

                bus_result = await asyncio.to_thread(bus_bot.solve_route, start_loc, end_loc)
                
                if bus_result.get("status") == "ambiguous":
                    return {
                        "answer": bus_result["message"], 
                        "options": bus_result["options"],
                        "context_type": "bus_ambiguity",
                        "original_request": {"start": start_loc, "end": end_loc, "type": bus_result["point_type"]},
                        "sources": [], "images": []
                    }

                if bus_result.get("status") == "error":
                    return {"answer": bus_result["message"], "sources": [], "images": []}
                
                raw_text = bus_result["text"]
                path_coords = bus_result.get("path_coords", [])
                
                google_link = ""
                if path_coords:
                    s = path_coords[0]
                    e = path_coords[-1]
                    google_link = f"https://www.google.com/maps/dir/?api=1&origin={s[1]},{s[0]}&destination={e[1]},{e[0]}&travelmode=transit"

                polish_prompt = f"""
                D·ªØ li·ªáu l·ªô tr√¨nh: \"\"\"{raw_text}\"\"\"
                Y√äU C·∫¶U: Vi·∫øt l·∫°i h∆∞·ªõng d·∫´n di chuy·ªÉn chuy√™n nghi·ªáp.
                1. Tr√¨nh b√†y c√°c b∆∞·ªõc r√µ r√†ng.
                2. In ƒë·∫≠m t√™n tr·∫°m, s·ªë xe.
                3. B·∫Øt bu·ªôc hi·ªÉn th·ªã B·∫£ng gi√° v√© (G·ªìm: V√© th∆∞·ªùng, HSSV, Ng∆∞·ªùi cao tu·ªïi).
                4. VƒÉn phong l·ªãch s·ª±, kh√¥ng emoji.
                """
                final_res = await asyncio.to_thread(llm_model.generate_content, polish_prompt)
                
                answer_text = final_res.text
                if google_link:
                    answer_text += f"\n\nüîó **[Xem b·∫£n ƒë·ªì l·ªô tr√¨nh tr√™n Google Maps]({google_link})**"

                return {"answer": answer_text, "sources": [], "images": []}
            except Exception as e:
                logger.error(f"BUS ERROR: {e}")
                return {"answer": "H·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi tra c·ª©u xe bu√Ωt. Vui l√≤ng th·ª≠ l·∫°i sau.", "sources": [], "images": []}
        else:
             return {"answer": "Vui l√≤ng cung c·∫•p ƒëi·ªÉm ƒëi v√† ƒëi·ªÉm ƒë·∫øn (V√≠ d·ª•: T·ª´ B·∫øn Th√†nh t·ªõi Aeon Mall) ƒë·ªÉ t√¥i t√¨m l·ªô tr√¨nh.", "sources": [], "images": []}

    # --- 4. X·ª¨ L√ù TOURISM / OOD ---
    
    # N·∫øu l√† Intent OOD (Y t·∫ø, IT...) -> Chuy·ªÉn th·∫≥ng sang Fallback ƒë·ªÉ t·ª´ ch·ªëi kh√©o
    if intent == "ood":
        general_answer = await fallback_general_knowledge(question)
        return {"answer": general_answer, "sources": [], "images": []}

    # X·ª≠ l√Ω Tourism
    final_province = request.province if request.province else location_filter
    
    # N·∫øu final_province l√† list, l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n l√†m text search ch√≠nh, nh∆∞ng v·∫´n gi·ªØ list ƒë·ªÉ filter
    search_query = question
    if isinstance(final_province, list) and len(final_province) > 0:
        # N·∫øu c√≥ ƒë·ªãa ƒëi·ªÉm tr√≠ch xu·∫•t ƒë∆∞·ª£c, ∆∞u ti√™n search theo ƒë·ªãa ƒëi·ªÉm ƒë√≥
        search_query = final_province[0]
    elif isinstance(final_province, str):
        search_query = final_province

    # S·ª≠ d·ª•ng h√†m clean ƒë·ªÉ search ch√≠nh x√°c h∆°n
    search_query = clean_entity_name(search_query)

    try:
        search_results = await hybrid_search_tourism(search_query, final_province)
    except Exception as e:
        logger.error(f"SEARCH ERROR: {e}")
        search_results = []
    
    if search_results:
        image_urls = []
        for item in search_results:
            node_data = item.get('node', {})
            url = node_data.get('image_url')
            if url and isinstance(url, str) and url.startswith("http"):
                image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2] 

        context_str = "\n".join([f"- {item['node']['name']} (T·ªânh: {item.get('province_name', 'Ch∆∞a r√µ')}): {item['node']['content']}" for item in search_results])
        
        if mode == "list":
            rag_prompt = f"""
            VAI TR√í: Tr·ª£ l√Ω du l·ªãch. NHI·ªÜM V·ª§: Li·ªát k√™.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U: Li·ªát k√™ (t·ªëi thi·ªÉu 3). Ghi r√µ T√™n v√† T·ªânh/Th√†nh. KH√îNG emoji.
            """
        else:
            rag_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a & du l·ªãch.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U: Ng·∫Øn g·ªçn. C·∫•u tr√∫c: 1. T·ªïng quan (V·ªã tr√≠ T·ªânh/Th√†nh), 2. G·∫°ch ƒë·∫ßu d√≤ng chi ti·∫øt.
            """

        res = await asyncio.to_thread(llm_model.generate_content, rag_prompt)
        return {"answer": res.text, "sources": search_results, "images": final_imgs}
    
    else:
        # --- FALLBACK KHI KH√îNG T√åM TH·∫§Y D·ªÆ LI·ªÜU ---
        # Ki·ªÉm tra xem c√≥ ph·∫£i c√¢u h·ªèi Toxic/Safety kh√¥ng ƒë·ªÉ t·ª´ ch·ªëi c·ª©ng
        general_answer = await fallback_general_knowledge(question)
        return {"answer": general_answer, "sources": [], "images": []}

# --- 5. API X·ª¨ L√ù ·∫¢NH (Gi·ªØ nguy√™n logic nh∆∞ng th√™m try-except an to√†n) ---
@app.post("/chat_with_image")
async def chat_with_image_endpoint(file: UploadFile = File(...), question: str = Form(...)):
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        vision_prompt = "ƒê√¢y l√† ƒë·ªãa ƒëi·ªÉm n√†o? Ch·ªâ tr·∫£ v·ªÅ t√™n ch√≠nh x√°c. N·∫øu kh√¥ng bi·∫øt, tr·∫£ v·ªÅ 'Unknown'."
        loop = asyncio.get_running_loop()
        vision_res = await loop.run_in_executor(None, lambda: llm_model.generate_content([vision_prompt, image]))
        detected_name = vision_res.text.strip()
        
        if "Unknown" in detected_name or len(detected_name) < 2:
             return {"detected_location": None, "answer": "Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ƒë·ªãa ƒëi·ªÉm trong ·∫£nh.", "sources": [], "images": []}
             
        search_results = await hybrid_search_tourism(detected_name)
        
        image_urls = []
        if search_results:
             for item in search_results:
                url = item.get('node', {}).get('image_url')
                if url and isinstance(url, str) and url.startswith("http"): image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2]

        if search_results:
            context_str = "\n".join([f"- {item['node']['name']}: {item['node']['content']}" for item in search_results[:3]])
            final_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a.
            ƒê·ªäA ƒêI·ªÇM: {detected_name}
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: {question}
            Y√äU C·∫¶U: Tr·∫£ l·ªùi chuy√™n nghi·ªáp. KH√îNG emoji.
            """
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(final_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": search_results, "images": final_imgs}
        else:
            general_prompt = f"ƒê·ªãa ƒëi·ªÉm: '{detected_name}'. C√¢u h·ªèi: '{question}'. Tr·∫£ l·ªùi chi ti·∫øt. KH√îNG emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(general_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": [], "images": []}

    except Exception as e:
        logger.error(f"IMAGE ERROR: {e}")
        return {"answer": "ƒê√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω h√¨nh ·∫£nh.", "sources": [], "images": []}