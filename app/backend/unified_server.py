import os
import logging
import asyncio
import unicodedata
import io
import json
import time
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from neo4j import AsyncGraphDatabase
import google.generativeai as genai
from PIL import Image

from bus_core import BusBotV13

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger(__name__)

load_dotenv(override=True)

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j") 
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

genai.configure(api_key=GEMINI_API_KEY)
llm_model = genai.GenerativeModel('gemini-2.0-flash') 

logger.info("SYSTEM: Loading Vector Model...")
model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")
logger.info("SYSTEM: Vector Model Loaded.")

tourism_driver = AsyncGraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
logger.info("SYSTEM: Initializing BusBot...")
bus_bot = BusBotV13()
logger.info("SYSTEM: BusBot Ready.")

def normalize_text(text: str) -> str:
    if not text: return ""
    return unicodedata.normalize('NFC', text).lower().strip()

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield
    await tourism_driver.close()
    bus_bot.close()

app = FastAPI(title="Professional Travel & Transport AI", lifespan=lifespan)
if os.path.exists("images_items"):
    app.mount("/images_items", StaticFiles(directory="images_items"), name="images")

# --- BLACKLIST GREETING ---
QUESTION_MARKERS = [
    "?", "l√† g√¨", "c√°i g√¨", "vi·ªác g√¨", "th·ª© g√¨", "ƒëi·ªÅu g√¨",
    "·ªü ƒë√¢u", "ch·ªó n√†o", "n∆°i n√†o", "khu n√†o", "ƒë√¢u",
    "khi n√†o", "l√∫c n√†o", "bao gi·ªù", "h·ªìi n√†o", "ng√†y n√†o",
    "ai", "ng∆∞·ªùi n√†o", "nh√¢n v·∫≠t n√†o", "v·ªã n√†o",
    "t·∫°i sao", "v√¨ sao", "nguy√™n nh√¢n", "l√Ω do", "sao l·∫°i",
    "th·∫ø n√†o", "ra sao", "nh∆∞ n√†o", "l√†m sao", "c√°ch n√†o",
    "bao nhi√™u", "bao l√¢u", "bao xa", "m·∫•y", "s·ªë l∆∞·ª£ng",
    "c√≥...kh√¥ng", "ƒë∆∞·ª£c kh√¥ng", "c√≥ ph·∫£i", "kh√¥ng ·∫°", "ch∆∞a", "h·∫£", "h·ª≠",
    "cho h·ªèi", "mu·ªën h·ªèi", "t√¨m hi·ªÉu", "ch·ªâ gi√∫p", "h∆∞·ªõng d·∫´n", "t∆∞ v·∫•n",
    "th√¥ng tin", "chi ti·∫øt", "gi·ªõi thi·ªáu", "k·ªÉ v·ªÅ", "n√≥i v·ªÅ"
]

# --- SEARCH LOGIC ---
async def hybrid_search_tourism(text: str, province_filter: str = None):
    search_text_norm = normalize_text(text)
    loop = asyncio.get_running_loop()
    vector = await loop.run_in_executor(None, lambda: model.encode(text).tolist())
    
    cypher_vector = "CALL db.index.vector.queryNodes('searchable_index', 50, $vector) YIELD node, score OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, score, p.name as province_name, 'vector' as source_type"
    cypher_keyword = "MATCH (node:Searchable) WHERE toLower(node.name) CONTAINS $text_norm OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, 1.0 as score, p.name as province_name, 'keyword' as source_type LIMIT 20"
    
    records = []
    async with tourism_driver.session() as session:
        try:
            r1 = await session.run(cypher_vector, vector=vector)
            records.extend([record.data() async for record in r1])
        except: pass
        try:
            r2 = await session.run(cypher_keyword, text_norm=search_text_norm)
            records.extend([record.data() async for record in r2])
        except: pass

    unique_results = {}
    for r in records:
        uid = r['id']
        if r['source_type'] == 'vector' and r['score'] < 0.70: continue
        if uid not in unique_results:
            unique_results[uid] = r
            unique_results[uid]['score'] = 10.0 if r['source_type'] == 'keyword' else r['score']
    
    return list(unique_results.values())[:5]

async def fallback_general_knowledge(question: str):
    system_prompt = f"""
    VAI TR√í: Chuy√™n gia t∆∞ v·∫•n du l·ªãch v√† vƒÉn h√≥a Vi·ªát Nam.
    C√ÇU H·ªéI: "{question}"
    Y√äU C·∫¶U:
    1. Tr·∫£ l·ªùi ch√≠nh x√°c, kh√°ch quan, ng√¥n ng·ªØ trang tr·ªçng (Professional Tone).
    2. KH√îNG s·ª≠ d·ª•ng Emoji.
    3. Tr√¨nh b√†y vƒÉn b·∫£n r√µ r√†ng b·∫±ng Markdown.
    4. T·∫≠p trung v√†o th√¥ng tin th·ª±c t·∫ø.
    """
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: llm_model.generate_content(system_prompt))
    return response.text

class ChatRequest(BaseModel):
    question: str
    province: Optional[str] = None

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()
    question = request.question.strip()
    logger.info(f"REQ: {question}")
    
    # 1. ROUTER
    router_prompt = f"""
    Ph√¢n t√≠ch c√¢u n√≥i: "{question}".
    H√£y x√°c ƒë·ªãnh Intent (√ù ƒë·ªãnh) ch√≠nh x√°c nh·∫•t:
    - "greeting": CH·ªà L√Ä c√¢u ch√†o h·ªèi x√£ giao thu·∫ßn t√∫y (Hello, Hi, Xin ch√†o...). 
      L∆ØU √ù: N·∫øu c√¢u ch·ª©a b·∫•t k·ª≥ n·ªôi dung h·ªèi ƒë√°p n√†o -> B·∫ÆT BU·ªòC ch·ªçn "tourism" ho·∫∑c "bus".
    - "bus": H·ªèi ƒë∆∞·ªùng ƒëi, xe bu√Ωt.
    - "tourism": H·ªèi th√¥ng tin, ki·∫øn th·ª©c, ƒë·ªãa ƒëi·ªÉm.
    Tr·∫£ v·ªÅ JSON: {{ "intent": "greeting" | "bus" | "tourism", "start_point": "...", "end_point": "..." }}
    """
    intent = "tourism"
    start_loc = None
    end_loc = None

    try:
        res = await asyncio.to_thread(llm_model.generate_content, router_prompt)
        clean = res.text.strip().replace("```json", "").replace("```", "")
        parsed = json.loads(clean)
        intent = parsed.get("intent", "tourism")
        start_loc = parsed.get("start_point")
        end_loc = parsed.get("end_point")
    except: pass

    # KILL SWITCH CHO GREETING
    lower_q = question.lower()
    has_question_word = any(marker in lower_q for marker in QUESTION_MARKERS)
    if has_question_word:
        if intent == "greeting": intent = "tourism"
        if "ƒë·∫øn" in lower_q and ("t·ª´" in lower_q or "ƒëi" in lower_q): intent = "bus"
    else:
        greeting_words = ["xin ch√†o", "hello", "hi bot", "ch√†o b·∫°n", "alo", "hi there", "ch√†o ad"]
        if any(w == lower_q or lower_q.startswith(w) for w in greeting_words) and len(lower_q) < 20:
            intent = "greeting"

    logger.info(f"üîç [INTENT]: {intent}")

    if intent == "greeting":
        greeting_msg = (
            "Xin ch√†o! T√¥i l√† Tr·ª£ l√Ω AI chuy√™n v·ªÅ Giao th√¥ng & VƒÉn h√≥a Vi·ªát Nam.\n\n"
            "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
            "- Tra c·ª©u l·ªô tr√¨nh xe bu√Ωt TP.HCM.\n"
            "- T√¨m hi·ªÉu vƒÉn h√≥a, l·ªãch s·ª≠, ·∫©m th·ª±c v√† du l·ªãch.\n\n"
            "B·∫°n ƒëang quan t√¢m ƒë·∫øn v·∫•n ƒë·ªÅ g√¨?"
        )
        logger.info(f"DONE [GREETING]: {time.time()-start_time:.2f}s")
        return {"answer": greeting_msg, "sources": [], "images": []}

    if intent == "bus" and (not start_loc or not end_loc):
        if "ƒë·∫øn" in lower_q:
            try:
                parts = lower_q.split("ƒë·∫øn")
                start_raw = parts[0]
                for w in ["ƒëi t·ª´", "t√¨m ƒë∆∞·ªùng t·ª´", "t·ª´", "ƒë∆∞·ªùng ƒëi"]:
                    start_raw = start_raw.replace(w, "")
                start_loc = start_raw.strip()
                end_loc = parts[1].strip()
            except: pass

    # 2. X·ª¨ L√ù BUS
    if intent == "bus":
        if start_loc and end_loc:
            try:
                bus_result = await asyncio.to_thread(bus_bot.solve_route, start_loc, end_loc)
                if bus_result.get("status") == "error":
                    return {"answer": bus_result["message"], "sources": [], "images": []}
                
                raw_text = bus_result["text"]
                path_coords = bus_result.get("path_coords", [])
                
                # --- T·∫†O LINK GOOGLE MAPS ---
                google_link = ""
                if path_coords:
                    # Coords t·ª´ Neo4j tr·∫£ v·ªÅ d·∫°ng [lng, lat]
                    # Google Maps c·∫ßn: origin=lat,lng & destination=lat,lng
                    s = path_coords[0]  # ƒêi·ªÉm ƒë·∫ßu [lng, lat]
                    e = path_coords[-1] # ƒêi·ªÉm cu·ªëi [lng, lat]
                    google_link = f"https://www.google.com/maps/dir/?api=1&origin={s[1]},{s[0]}&destination={e[1]},{e[0]}&travelmode=transit"

                polish_prompt = f"""
                D·ªØ li·ªáu l·ªô tr√¨nh: \"\"\"{raw_text}\"\"\"
                Y√äU C·∫¶U: Vi·∫øt l·∫°i h∆∞·ªõng d·∫´n di chuy·ªÉn chuy√™n nghi·ªáp, r√µ r√†ng.
                - D√πng danh s√°ch s·ªë (1., 2., 3.).
                - In ƒë·∫≠m t√™n tr·∫°m, s·ªë xe.
                - KH√îNG d√πng emoji.
                - HI·ªÇN TH·ªä ƒê·∫¶Y ƒê·ª¶ GI√Å V√â (T·ª´ng ch·∫∑ng v√† T·ªïng c·ªông).
                """
                final_res = await asyncio.to_thread(llm_model.generate_content, polish_prompt)
                
                answer_text = final_res.text
                if google_link:
                    answer_text += f"\n\nüîó **[B·∫•m v√†o ƒë√¢y ƒë·ªÉ xem b·∫£n ƒë·ªì tr√™n Google Maps]({google_link})**"

                logger.info(f"DONE [BUS]: {time.time()-start_time:.2f}s")
                # L∆ØU √ù: Kh√¥ng tr·∫£ v·ªÅ path_coords ƒë·ªÉ Client kh√¥ng v·∫Ω map
                return {"answer": answer_text, "sources": [], "images": []}
            except Exception as e:
                return {"answer": f"L·ªói h·ªá th·ªëng: {str(e)}", "sources": [], "images": []}
        else:
            return {"answer": "Vui l√≤ng cung c·∫•p ƒëi·ªÉm ƒëi v√† ƒëi·ªÉm ƒë·∫øn ƒë·ªÉ t√¥i t√¨m l·ªô tr√¨nh xe bu√Ωt.", "sources": [], "images": []}

    # 3. X·ª¨ L√ù TOURISM
    search_results = await hybrid_search_tourism(question, request.province)
    if search_results:
        image_urls = []
        for item in search_results[:3]:
            node_data = item.get('node', {})
            url = node_data.get('image_url') or node_data.get('image')
            if url and isinstance(url, str) and url.startswith("http"):
                image_urls.append(url)
        seen = set()
        uniq_imgs = [x for x in image_urls if not (x in seen or seen.add(x))]

        context_str = "\n".join([f"- {item['node']['name']}: {item['node']['content']}" for item in search_results])
        rag_prompt = f"""
        B·∫°n l√† chuy√™n gia vƒÉn h√≥a/du l·ªãch. D·ªÆ LI·ªÜU: {context_str}. C√ÇU H·ªéI: "{question}"
        Y√äU C·∫¶U: Tr·∫£ l·ªùi chuy√™n nghi·ªáp, kh√°ch quan, Markdown. KH√îNG d√πng emoji.
        """
        res = await asyncio.to_thread(llm_model.generate_content, rag_prompt)
        logger.info(f"DONE [RAG]: {time.time()-start_time:.2f}s")
        return {"answer": res.text, "sources": search_results, "images": uniq_imgs}
    else:
        general_answer = await fallback_general_knowledge(question)
        logger.info(f"DONE [FALLBACK]: {time.time()-start_time:.2f}s")
        return {"answer": general_answer, "sources": [], "images": []}

@app.post("/chat_with_image")
async def chat_with_image_endpoint(file: UploadFile = File(...), question: str = Form(...)):
    start_time = time.time()
    logger.info(f"REQ [IMG]: {question}")
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        vision_prompt = "ƒê√¢y l√† ƒë·ªãa ƒëi·ªÉm n√†o? Ch·ªâ tr·∫£ v·ªÅ t√™n ch√≠nh x√°c. N·∫øu kh√¥ng bi·∫øt, tr·∫£ v·ªÅ 'Unknown'."
        loop = asyncio.get_running_loop()
        vision_res = await loop.run_in_executor(None, lambda: llm_model.generate_content([vision_prompt, image]))
        detected_name = vision_res.text.strip()
        
        if "Unknown" in detected_name or len(detected_name) < 2:
             return {"detected_location": None, "answer": "H·ªá th·ªëng ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ƒë·ªãa ƒëi·ªÉm trong ·∫£nh.", "sources": [], "images": []}
             
        search_results = await hybrid_search_tourism(detected_name)
        image_urls = []
        if search_results:
             for item in search_results[:1]:
                node_data = item.get('node', {})
                url = node_data.get('image_url') or node_data.get('image')
                if url and isinstance(url, str) and url.startswith("http"): image_urls.append(url)

        if search_results:
            context_str = "\n".join([f"- {item['name']}: {item['content']}" for item in search_results[:3]])
            final_prompt = f"ƒê·ªãa ƒëi·ªÉm: {detected_name}. D·ªØ li·ªáu: {context_str}. C√¢u h·ªèi: {question}. Y√™u c·∫ßu tr·∫£ l·ªùi chuy√™n nghi·ªáp, kh√¥ng emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(final_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": search_results, "images": image_urls}
        else:
            general_prompt = f"ƒê·ªãa ƒëi·ªÉm trong ·∫£nh l√† '{detected_name}'. C√¢u h·ªèi: '{question}'. H√£y tr·∫£ l·ªùi chi ti·∫øt v·ªõi vƒÉn phong chuy√™n gia, kh√¥ng d√πng emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(general_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": [], "images": []}

    except Exception as e:
        logger.error(f"ERROR: {e}")
        return {"answer": "ƒê√£ x·∫£y ra l·ªói x·ª≠ l√Ω ·∫£nh.", "sources": [], "images": []}