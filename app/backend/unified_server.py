import os
import logging
import asyncio
import unicodedata
import io
import json
import time
from typing import Optional
from contextlib import asynccontextmanager

from fastapi import FastAPI, UploadFile, File, Form
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from neo4j import AsyncGraphDatabase
import google.generativeai as genai
from PIL import Image

from bus_core import BusBotV13

# --- 1. C·∫§U H√åNH LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
logger = logging.getLogger(__name__)

# --- 2. LOAD BI·∫æN M√îI TR∆Ø·ªúNG ---
load_dotenv(override=True)

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USERNAME", "neo4j") 
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 

# --- 3. KH·ªûI T·∫†O MODEL & DB ---
if not GEMINI_API_KEY:
    logger.error("‚ùå CH∆ØA C√ì GEMINI_API_KEY TRONG FILE .ENV")

genai.configure(api_key=GEMINI_API_KEY)
llm_model = genai.GenerativeModel('gemini-2.0-flash') 

logger.info("SYSTEM: Loading Vector Model...")
model = SentenceTransformer("bkai-foundation-models/vietnamese-bi-encoder")
logger.info("SYSTEM: Vector Model Loaded.")

tourism_driver = AsyncGraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
logger.info("SYSTEM: Initializing BusBot...")
bus_bot = BusBotV13()
logger.info("SYSTEM: BusBot Ready.")

def normalize_text(text: str) -> str:
    if not text: return ""
    return unicodedata.normalize('NFC', text).lower().strip()

@asynccontextmanager
async def lifespan(app: FastAPI):
    yield
    await tourism_driver.close()
    bus_bot.close()

app = FastAPI(title="Professional Travel & Transport AI", lifespan=lifespan)

if not os.path.exists("images_items"):
    os.makedirs("images_items")
app.mount("/images_items", StaticFiles(directory="images_items"), name="images")

# --- 4. DANH S√ÅCH T·ª™ KH√ìA ---
QUESTION_MARKERS = [
    "?", "l√† g√¨", "c√°i g√¨", "vi·ªác g√¨", "th·ª© g√¨", "ƒëi·ªÅu g√¨",
    "·ªü ƒë√¢u", "ch·ªó n√†o", "n∆°i n√†o", "khu n√†o", "ƒë√¢u",
    "khi n√†o", "l√∫c n√†o", "bao gi·ªù", "h·ªìi n√†o", "ng√†y n√†o",
    "ai", "ng∆∞·ªùi n√†o", "nh√¢n v·∫≠t n√†o", "v·ªã n√†o",
    "t·∫°i sao", "v√¨ sao", "nguy√™n nh√¢n", "l√Ω do", "sao l·∫°i",
    "th·∫ø n√†o", "ra sao", "nh∆∞ n√†o", "l√†m sao", "c√°ch n√†o",
    "bao nhi√™u", "bao l√¢u", "bao xa", "m·∫•y", "s·ªë l∆∞·ª£ng",
    "c√≥...kh√¥ng", "ƒë∆∞·ª£c kh√¥ng", "c√≥ ph·∫£i", "kh√¥ng ·∫°", "ch∆∞a", "h·∫£", "h·ª≠",
    "cho h·ªèi", "mu·ªën h·ªèi", "t√¨m hi·ªÉu", "ch·ªâ gi√∫p", "h∆∞·ªõng d·∫´n", "t∆∞ v·∫•n",
    "th√¥ng tin", "chi ti·∫øt", "gi·ªõi thi·ªáu", "k·ªÉ v·ªÅ", "n√≥i v·ªÅ", "li·ªát k√™", "danh s√°ch"
]

# --- 5. LOGIC T√åM KI·∫æM TOURISM ---
async def hybrid_search_tourism(text: str, province_filter: str = None):
    search_text_norm = normalize_text(text)
    records = []
    
    async with tourism_driver.session() as session:
        # TH1: C√≥ l·ªçc theo t·ªânh -> T√¨m ki·∫øm di·ªán r·ªông
        if province_filter and len(province_filter) > 2:
            province_norm = normalize_text(province_filter)
            cypher_loc = """
            MATCH (node:Searchable)-[:LOCATED_IN]->(p:Province)
            WHERE toLower(p.name) CONTAINS $province_norm
            AND (toLower(node.name) CONTAINS $text_norm OR toLower(node.content) CONTAINS $text_norm)
            RETURN elementId(node) as id, node, 1.5 as score, p.name as province_name, 'location_filter' as source_type
            LIMIT 15
            """
            try:
                r_loc = await session.run(cypher_loc, province_norm=province_norm, text_norm=search_text_norm)
                records.extend([record.data() async for record in r_loc])
            except Exception as e:
                logger.error(f"Error Loc Search: {e}")

        # TH2: Vector & Keyword Search
        if len(records) < 5: 
            loop = asyncio.get_running_loop()
            vector = await loop.run_in_executor(None, lambda: model.encode(text).tolist())
            
            cypher_vector = "CALL db.index.vector.queryNodes('searchable_index', 50, $vector) YIELD node, score OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, score, p.name as province_name, 'vector' as source_type"
            cypher_keyword = "MATCH (node:Searchable) WHERE toLower(node.name) CONTAINS $text_norm OPTIONAL MATCH (node)-[:LOCATED_IN]->(p:Province) RETURN elementId(node) as id, node, 1.0 as score, p.name as province_name, 'keyword' as source_type LIMIT 20"
            
            try:
                r1 = await session.run(cypher_vector, vector=vector)
                records.extend([record.data() async for record in r1])
            except: pass
            try:
                r2 = await session.run(cypher_keyword, text_norm=search_text_norm)
                records.extend([record.data() async for record in r2])
            except: pass

    unique_results = {}
    for r in records:
        uid = r['id']
        if province_filter and r.get('province_name'):
            if normalize_text(province_filter) not in normalize_text(r['province_name']):
                r['score'] = r['score'] * 0.1
        if r['source_type'] == 'vector' and r['score'] < 0.65: continue
        
        if uid not in unique_results:
            unique_results[uid] = r
            if r['source_type'] == 'location_filter':
                unique_results[uid]['score'] = 10.0
            else:
                unique_results[uid]['score'] = 10.0 if r['source_type'] == 'keyword' else r['score']
    
    sorted_results = sorted(unique_results.values(), key=lambda x: x['score'], reverse=True)
    return sorted_results[:10]

# --- 6. FALLBACK LOGIC ---
async def fallback_general_knowledge(question: str):
    system_prompt = f"""
    VAI TR√í: Chuy√™n gia t∆∞ v·∫•n du l·ªãch v√† vƒÉn h√≥a Vi·ªát Nam.
    C√ÇU H·ªéI: "{question}"
    Y√äU C·∫¶U: Tr·∫£ l·ªùi ch√≠nh x√°c, kh√°ch quan, ng√¥n ng·ªØ trang tr·ªçng. KH√îNG d√πng Emoji.
    """
    loop = asyncio.get_running_loop()
    response = await loop.run_in_executor(None, lambda: llm_model.generate_content(system_prompt))
    return response.text

class ChatRequest(BaseModel):
    question: str
    province: Optional[str] = None

# ==========================================
#               MAIN CHAT API
# ==========================================
@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    start_time = time.time()
    question = request.question.strip()
    logger.info(f"REQ: {question}")
    lower_q = question.lower()
    
    # --- 1. ROUTER TH√îNG MINH ---
    # Danh s√°ch t·ª´ n·ªëi ƒë·ªÉ nh·∫≠n di·ªán c√¢u h·ªèi Bus
    # Bao g·ªìm: ƒë·∫øn, t·ªõi, v·ªÅ, sang, qua, ra
    dest_markers = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "] 
    
    is_bus_intent = False
    # Check nhanh: N·∫øu c√≥ t·ª´ ch·ªâ h∆∞·ªõng + t·ª´ ch·ªâ di chuy·ªÉn
    if any(m.strip() in lower_q for m in dest_markers) and \
       any(w in lower_q for w in ["t·ª´", "ƒëi", "ƒë∆∞·ªùng", "xe bus", "bu√Ωt", "c√°ch"]):
        is_bus_intent = True

    router_prompt = f"""
    Ph√¢n t√≠ch c√¢u h·ªèi: "{question}".
    Nhi·ªám v·ª•:
    1. Intent: "greeting" | "bus" | "tourism".
    2. Location: Tr√≠ch xu·∫•t t√™n T·ªânh/Th√†nh ph·ªë (n·∫øu c√≥).
    3. Mode: "list" (li·ªát k√™) | "detail" (chi ti·∫øt).
    
    JSON Output: {{ "intent": "...", "location": "...", "mode": "..." }}
    """
    
    intent = "bus" if is_bus_intent else "tourism"
    location_filter = None
    mode = "detail"

    try:
        if not is_bus_intent: # Ch·ªâ d√πng AI check n·∫øu ch∆∞a ch·∫Øc l√† Bus
            res = await asyncio.to_thread(llm_model.generate_content, router_prompt)
            clean = res.text.strip().replace("```json", "").replace("```", "")
            parsed = json.loads(clean)
            intent = parsed.get("intent", "tourism")
            location_filter = parsed.get("location")
            mode = parsed.get("mode", "detail")
    except: pass

    # Override Intent th·ªß c√¥ng n·∫øu ph√°t hi·ªán t·ª´ kh√≥a m·∫°nh
    if is_bus_intent: intent = "bus"
    
    has_question_word = any(marker in lower_q for marker in QUESTION_MARKERS)
    if intent != "bus":
        if has_question_word:
            if intent == "greeting": intent = "tourism"
        else:
            greeting_words = ["xin ch√†o", "hello", "hi bot", "ch√†o b·∫°n", "alo"]
            if any(w == lower_q or lower_q.startswith(w) for w in greeting_words) and len(lower_q) < 20:
                intent = "greeting"

    if location_filter and mode == "detail":
        if any(w in lower_q for w in ["n√†o", "g√¨", "nh·ªØng", "c√°c"]): mode = "list"

    logger.info(f"üîç INTENT: {intent} | LOC: {location_filter} | MODE: {mode}")

    if intent == "greeting":
        return {"answer": "K√≠nh ch√†o Qu√Ω kh√°ch. T√¥i l√† Tr·ª£ l√Ω AI chuy√™n tr√°ch v·ªÅ VƒÉn h√≥a & Giao th√¥ng.\nT√¥i c√≥ th·ªÉ gi√∫p b·∫°n tra c·ª©u l·ªô tr√¨nh xe bu√Ωt ho·∫∑c th√¥ng tin du l·ªãch.", "sources": [], "images": []}

    # --- X·ª¨ L√ù BUS (LOGIC T√ÅCH CHU·ªñI N√ÇNG CAO) ---
    if intent == "bus":
        start_loc = None
        end_loc = None
        
        # Danh s√°ch c√°c t·ª´ c√≥ th·ªÉ l√† v√°ch ngƒÉn gi·ªØa ƒêi·ªÉm ƒëi v√† ƒêi·ªÉm ƒë·∫øn
        # L∆∞u √Ω: C√≥ kho·∫£ng tr·∫Øng 2 ƒë·∫ßu ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm (vd: "Qu·ªëc l·ªô" c√≥ ch·ªØ "qua")
        separators = [" ƒë·∫øn ", " t·ªõi ", " v·ªÅ ", " sang ", " qua ", " ra "]
        
        # Danh s√°ch t·ª´ th·ª´a ·ªü ƒë·∫ßu c√¢u c·∫ßn c·∫Øt b·ªè
        start_prefixes = ["ƒëi t·ª´", "t·ª´", "t√¨m ƒë∆∞·ªùng t·ª´", "ch·ªâ ƒë∆∞·ªùng t·ª´", "ƒë∆∞·ªùng ƒëi t·ª´", "l·ªô tr√¨nh t·ª´", "xe bu√Ωt t·ª´", "b·∫Øt xe t·ª´"]

        found_sep = None
        # T√¨m t·ª´ n·ªëi xu·∫•t hi·ªán ƒë·∫ßu ti√™n trong c√¢u
        for sep in separators:
            if sep in lower_q:
                found_sep = sep
                break
        
        if found_sep:
            try:
                parts = lower_q.split(found_sep, 1) # Ch·ªâ t√°ch ·ªü t·ª´ n·ªëi ƒë·∫ßu ti√™n
                end_loc = parts[1].strip()
                
                # X·ª≠ l√Ω ph·∫ßn Start: C·∫Øt b·ªè c√°c t·ª´ prefix
                start_raw = parts[0].strip()
                for prefix in start_prefixes:
                    if start_raw.startswith(prefix):
                        start_raw = start_raw[len(prefix):].strip()
                        break # C·∫Øt xong th√¨ th√¥i
                start_loc = start_raw
            except: pass
        
        if start_loc and end_loc:
            try:
                # G·ªçi BusBot
                bus_result = await asyncio.to_thread(bus_bot.solve_route, start_loc, end_loc)
                
                # TH1: Ambiguous -> Tr·∫£ v·ªÅ Options
                if bus_result.get("status") == "ambiguous":
                    return {
                        "answer": bus_result["message"], 
                        "options": bus_result["options"],
                        "context_type": "bus_ambiguity",
                        "original_request": {"start": start_loc, "end": end_loc, "type": bus_result["point_type"]},
                        "sources": [], "images": []
                    }

                # TH2: Error
                if bus_result.get("status") == "error":
                    return {"answer": bus_result["message"], "sources": [], "images": []}
                
                # TH3: Th√†nh c√¥ng
                raw_text = bus_result["text"]
                path_coords = bus_result.get("path_coords", [])
                
                google_link = ""
                if path_coords:
                    s = path_coords[0]
                    e = path_coords[-1]
                    google_link = f"https://www.google.com/maps/dir/?api=1&origin={s[1]},{s[0]}&destination={e[1]},{e[0]}&travelmode=transit"

                polish_prompt = f"""
                D·ªØ li·ªáu l·ªô tr√¨nh: \"\"\"{raw_text}\"\"\"
                Y√äU C·∫¶U: Vi·∫øt l·∫°i h∆∞·ªõng d·∫´n di chuy·ªÉn chuy√™n nghi·ªáp.
                1. Tr√¨nh b√†y c√°c b∆∞·ªõc r√µ r√†ng.
                2. In ƒë·∫≠m t√™n tr·∫°m, s·ªë xe.
                3. B·∫Øt bu·ªôc hi·ªÉn th·ªã B·∫£ng gi√° v√© (G·ªìm: V√© th∆∞·ªùng, HSSV, Ng∆∞·ªùi cao tu·ªïi).
                4. VƒÉn phong l·ªãch s·ª±, kh√¥ng emoji.
                """
                final_res = await asyncio.to_thread(llm_model.generate_content, polish_prompt)
                
                answer_text = final_res.text
                if google_link:
                    answer_text += f"\n\nüîó **[Xem b·∫£n ƒë·ªì l·ªô tr√¨nh tr√™n Google Maps]({google_link})**"

                return {"answer": answer_text, "sources": [], "images": []}
            except Exception as e:
                return {"answer": f"L·ªói h·ªá th·ªëng: {str(e)}", "sources": [], "images": []}
        else:
             return {"answer": "Vui l√≤ng cung c·∫•p ƒëi·ªÉm ƒëi v√† ƒëi·ªÉm ƒë·∫øn (V√≠ d·ª•: T·ª´ B·∫øn Th√†nh t·ªõi Aeon Mall) ƒë·ªÉ t√¥i t√¨m l·ªô tr√¨nh.", "sources": [], "images": []}

    # --- X·ª¨ L√ù TOURISM ---
    final_province = request.province if request.province else location_filter
    search_results = await hybrid_search_tourism(question, final_province)
    
    if search_results:
        image_urls = []
        for item in search_results:
            node_data = item.get('node', {})
            url = node_data.get('image_url')
            if url and isinstance(url, str) and url.startswith("http"):
                image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2] 

        context_str = "\n".join([f"- {item['node']['name']} (T·ªânh: {item.get('province_name', 'Ch∆∞a r√µ')}): {item['node']['content']}" for item in search_results])
        
        if mode == "list":
            rag_prompt = f"""
            VAI TR√í: Tr·ª£ l√Ω du l·ªãch.
            NHI·ªÜM V·ª§: Li·ªát k√™ ƒë·ªãa ƒëi·ªÉm.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U: Li·ªát k√™ danh s√°ch (t·ªëi thi·ªÉu 3). Ghi r√µ T√™n v√† T·ªânh/Th√†nh ph·ªë. M√¥ t·∫£ ng·∫Øn. KH√îNG emoji.
            """
        else:
            rag_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a & du l·ªãch.
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: "{question}"
            Y√äU C·∫¶U:
            1. PHONG C√ÅCH: Ng·∫Øn g·ªçn, s√∫c t√≠ch.
            2. C·∫§U TR√öC:
               - ƒêo·∫°n 1: T·ªïng quan (T√™n, V·ªã tr√≠ h√†nh ch√≠nh c·ª• th·ªÉ T·ªânh/Th√†nh, ƒë·∫∑c ƒëi·ªÉm).
               - ƒêo·∫°n 2: G·∫°ch ƒë·∫ßu d√≤ng t√≥m t·∫Øt (V·ªã tr√≠, L·ªãch s·ª≠, Ki·∫øn tr√∫c, Gi√° tr·ªã).
            3. D√πng th√¥ng tin T·ªânh/Th√†nh c√≥ trong d·ªØ li·ªáu. KH√îNG m·ªü b√†i/k·∫øt b√†i r∆∞·ªùm r√†.
            """

        res = await asyncio.to_thread(llm_model.generate_content, rag_prompt)
        return {"answer": res.text, "sources": search_results, "images": final_imgs}
    
    else:
        general_answer = await fallback_general_knowledge(question)
        return {"answer": general_answer, "sources": [], "images": []}

# --- API X·ª¨ L√ù ·∫¢NH ---
@app.post("/chat_with_image")
async def chat_with_image_endpoint(file: UploadFile = File(...), question: str = Form(...)):
    try:
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        vision_prompt = "ƒê√¢y l√† ƒë·ªãa ƒëi·ªÉm n√†o? Ch·ªâ tr·∫£ v·ªÅ t√™n ch√≠nh x√°c. N·∫øu kh√¥ng bi·∫øt, tr·∫£ v·ªÅ 'Unknown'."
        loop = asyncio.get_running_loop()
        vision_res = await loop.run_in_executor(None, lambda: llm_model.generate_content([vision_prompt, image]))
        detected_name = vision_res.text.strip()
        
        if "Unknown" in detected_name or len(detected_name) < 2:
            return {"detected_location": None, "answer": "Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ƒë·ªãa ƒëi·ªÉm.", "sources": [], "images": []}
             
        search_results = await hybrid_search_tourism(detected_name)
        
        image_urls = []
        if search_results:
            for item in search_results:
                url = item.get('node', {}).get('image_url')
                if url and isinstance(url, str) and url.startswith("http"): 
                    image_urls.append(url)
        final_imgs = list(dict.fromkeys(image_urls))[:2]

        if search_results:
            context_str = "\n".join([f"- {item['node']['name']} (T·ªânh: {item.get('province_name', '')}): {item['node']['content']}" for item in search_results[:3]])
            final_prompt = f"""
            VAI TR√í: Chuy√™n gia vƒÉn h√≥a.
            ƒê·ªäA ƒêI·ªÇM T·ª™ ·∫¢NH: {detected_name}
            D·ªÆ LI·ªÜU: {context_str}
            C√ÇU H·ªéI: {question}
            Y√äU C·∫¶U: Tr·∫£ l·ªùi chuy√™n nghi·ªáp, c·∫•u tr√∫c r√µ r√†ng (T√™n, V·ªã tr√≠ T·ªânh/Th√†nh, ƒê·∫∑c ƒëi·ªÉm), KH√îNG emoji.
            """
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(final_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": search_results, "images": final_imgs}
        else:
            general_prompt = f"ƒê·ªãa ƒëi·ªÉm trong ·∫£nh l√† '{detected_name}'. C√¢u h·ªèi: '{question}'. Tr·∫£ l·ªùi chi ti·∫øt, n√™u r√µ v·ªã tr√≠ thu·ªôc T·ªânh/Th√†nh n√†o. KH√îNG emoji."
            final_res = await loop.run_in_executor(None, lambda: llm_model.generate_content(general_prompt))
            return {"detected_location": detected_name, "answer": final_res.text, "sources": [], "images": []}

    except Exception as e:
        logger.error(f"ERROR: {e}")
        return {"answer": "L·ªói x·ª≠ l√Ω ·∫£nh.", "sources": [], "images": []}